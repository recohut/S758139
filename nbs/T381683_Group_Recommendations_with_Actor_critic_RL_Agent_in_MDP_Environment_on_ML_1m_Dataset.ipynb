{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T381683 | Group Recommendations with Actor-critic RL Agent in MDP Environment on ML-1m Dataset",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1xBn4HDiXTzxOUsCgEh9WymDFl9Ldo7O6",
      "authorship_tag": "ABX9TyPxni6punX/HWxLvrzJ68c2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sparsh-ai/stanza/blob/S758139/T381683_Group_Recommendations_with_Actor_critic_RL_Agent_in_MDP_Environment_on_ML_1m_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdBrR-7dC3S_"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GzyMaFcDdrv"
      },
      "source": [
        "- **Problem:** Group recommendation problem is challenging because recommending some item that satisfies all the members of the group is rare. So it often involves some compromises that the model has to make in order to maximize the overall satisfaction of the group.\n",
        "- **Hypothesis:** RL agent can learn the required behavior that could the maximize the group's overall satisfaction.\n",
        "- **Benefits:** Meaningful to those people who want to get recommendations for their groups, such as entertainments with families and travels with friends. This model consider the influences of each group member by one self-attention mechanism.\n",
        "- **Solution:** A recommender agent is trained with actor-critic network and is optimized with DDPG algorithm, where the experience replay and target networks are used. Matrix factorization based simulator is built to simulate the MDP environment. It is an extended version of LIRD model for group recommendations. The group recommendation is viewed as a classification task. When one item is recommended to a group, if the group chooses the item, this case is marked as a positive sample. Otherwise, it will be a negative sample.\n",
        "- **Dataset:** MovieLens-1m\n",
        "- **Preprocessing:** Randomly generate groups with 2-5 users. Then, for each group, if every member gives 4-5 stars to one movie, we assume that this movie is adopted by this group with rating 1. If all members give ratings to one movie, but not all in 4-5 stars, we consider the group gives rating 0 to this movie. For other cases, the group movie ratings are missed. Finally, to ensure each group has enough interactions with items, we require each group has at least 20 ratings. Also, for each rating, 100 rating-missed items are randomly sampled. Both user and group rating data are split into training, validation, and testing datasets with the ratio of 70%, 10%, and 20% respectively by the temporal order.\n",
        "- **Metrics:** Recall, nDCG\n",
        "- **Cluster:** PyTorch 1.10 cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZibVhj4EYiH"
      },
      "source": [
        "`ActorCriticNetwork`, `DDPG`, `GroupRecommendation`, `MovieLens1M`, `PyTorch`, `ReplayMemory`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0m6N7IjYC3PK"
      },
      "source": [
        "<img src='https://github.com/sparsh-ai/stanza/raw/S758139/images/group_recommender_actorcritic_1.svg'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7RfxQkfNMBp"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrwfSRelM24I"
      },
      "source": [
        "from typing import Tuple, List, Dict\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse import coo_matrix, csr_matrix\n",
        "from collections import deque, defaultdict\n",
        "import shutil\n",
        "import zipfile\n",
        "import scipy.sparse as sp\n",
        "from collections import Counter\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as functional\n",
        "from torch import optim, nn\n",
        "\n",
        "import gym\n",
        "from sklearn.decomposition import NMF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA0gzRH0NXV6"
      },
      "source": [
        "class Config(object):\n",
        "    \"\"\"\n",
        "    Configurations\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Data\n",
        "        self.data_folder_path = os.path.join('data', 'MovieLens-Rand')\n",
        "        self.item_path = os.path.join(self.data_folder_path, 'movies.dat')\n",
        "        self.user_path = os.path.join(self.data_folder_path, 'users.dat')\n",
        "        self.group_path = os.path.join(self.data_folder_path, 'groupMember.dat')\n",
        "        self.saves_folder_path = os.path.join('saves')\n",
        "\n",
        "        # Recommendation system\n",
        "        self.history_length = 5\n",
        "        self.top_K_list = [5, 10, 20]\n",
        "        self.rewards = [0, 1]\n",
        "\n",
        "        # Reinforcement learning\n",
        "        self.embedding_size = 32\n",
        "        self.state_size = self.history_length + 1\n",
        "        self.action_size = 1\n",
        "        self.embedded_state_size = self.state_size * self.embedding_size\n",
        "        self.embedded_action_size = self.action_size * self.embedding_size\n",
        "\n",
        "        # Numbers\n",
        "        self.item_num = None\n",
        "        self.user_num = None\n",
        "        self.group_num = None\n",
        "        self.total_group_num = None\n",
        "\n",
        "        # Environment\n",
        "        self.env_n_components = self.embedding_size\n",
        "        self.env_tol = 1e-4\n",
        "        self.env_max_iter = 1000\n",
        "        self.env_alpha = 0.001\n",
        "\n",
        "        # Actor-Critic network\n",
        "        self.actor_hidden_sizes = (128, 64)\n",
        "        self.critic_hidden_sizes = (32, 16)\n",
        "\n",
        "        # DDPG algorithm\n",
        "        self.tau = 1e-3\n",
        "        self.gamma = 0.9\n",
        "\n",
        "        # Optimizer\n",
        "        self.batch_size = 64\n",
        "        self.buffer_size = 100000\n",
        "        self.num_episodes = 10 # recommended = 1000\n",
        "        self.num_steps = 5 # recommended = 100\n",
        "        self.embedding_weight_decay = 1e-6\n",
        "        self.actor_weight_decay = 1e-6\n",
        "        self.critic_weight_decay = 1e-6\n",
        "        self.embedding_learning_rate = 1e-4\n",
        "        self.actor_learning_rate = 1e-4\n",
        "        self.critic_learning_rate = 1e-4\n",
        "        self.eval_per_iter = 10\n",
        "\n",
        "        # OU noise\n",
        "        self.ou_mu = 0.0\n",
        "        self.ou_theta = 0.15\n",
        "        self.ou_sigma = 0.2\n",
        "        self.ou_epsilon = 1.0\n",
        "\n",
        "        # GPU\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = torch.device(\"cuda:0\")\n",
        "        else:\n",
        "            self.device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cXG75oPNwhd"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E41yGTR-Nxae"
      },
      "source": [
        "class OUNoise(object):\n",
        "    \"\"\"\n",
        "    Ornstein-Uhlenbeck Noise\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        \"\"\"\n",
        "        Initialize OUNoise\n",
        "        :param config: configurations\n",
        "        \"\"\"\n",
        "        self.embedded_action_size = config.embedded_action_size\n",
        "        self.ou_mu = config.ou_mu\n",
        "        self.ou_theta = config.ou_theta\n",
        "        self.ou_sigma = config.ou_sigma\n",
        "        self.ou_epsilon = config.ou_epsilon\n",
        "        self.ou_state = None\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reset the OU process state\n",
        "        \"\"\"\n",
        "        self.ou_state = torch.ones(self.embedded_action_size) * self.ou_mu\n",
        "\n",
        "    def evolve_state(self):\n",
        "        \"\"\"\n",
        "        Evolve the OU process state\n",
        "        \"\"\"\n",
        "        self.ou_state += self.ou_theta * (self.ou_mu - self.ou_state) \\\n",
        "            + self.ou_sigma * torch.randn(self.embedded_action_size)\n",
        "\n",
        "    def get_ou_noise(self):\n",
        "        \"\"\"\n",
        "        Get the OU noise for one action\n",
        "        :return OU noise\n",
        "        \"\"\"\n",
        "        self.evolve_state()\n",
        "        return self.ou_state.copy()\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "    \"\"\"\n",
        "    Replay Memory\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, buffer_size: int):\n",
        "        \"\"\"\n",
        "        Initialize ReplayMemory\n",
        "        :param buffer_size: size of the buffer\n",
        "        \"\"\"\n",
        "        self.buffer_size = buffer_size\n",
        "        self.buffer = deque(maxlen=buffer_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.buffer)\n",
        "\n",
        "    def push(self, experience: tuple):\n",
        "        \"\"\"\n",
        "        Push one experience into the buffer\n",
        "        :param experience: (state, action, reward, new_state)\n",
        "        \"\"\"\n",
        "        self.buffer.append(experience)\n",
        "\n",
        "    def sample(self, batch_size: int):\n",
        "        \"\"\"\n",
        "        Sample one batch from the buffer\n",
        "        :param batch_size: number of experiences in the batch\n",
        "        :return: batch\n",
        "        \"\"\"\n",
        "        batch = random.sample(self.buffer, batch_size)\n",
        "        return batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "np-rYYhl3FLW"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HgBIqbqF81t"
      },
      "source": [
        "<img src='https://github.com/sparsh-ai/stanza/raw/S758139/images/group_recommender_actorcritic_2.svg'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asSkk-313FIZ"
      },
      "source": [
        "!wget -q --show-progress https://files.grouplens.org/datasets/movielens/ml-1m.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSP785vg3FFP"
      },
      "source": [
        "class GroupGenerator(object):\n",
        "    \"\"\"\n",
        "    Group Data Generator\n",
        "    \"\"\"\n",
        "    def __init__(self, data_path, output_path, rating_threshold, num_groups,\n",
        "                 group_sizes, min_num_ratings, train_ratio, val_ratio,\n",
        "                 negative_sample_size, verbose=False):\n",
        "        self.rating_threshold = rating_threshold\n",
        "        self.negative_sample_size = negative_sample_size\n",
        "        users_path = os.path.join(data_path, 'users.dat')\n",
        "        items_path = os.path.join(data_path, 'movies.dat')\n",
        "        ratings_path = os.path.join(data_path, 'ratings.dat')\n",
        "\n",
        "        users = self.load_users_file(users_path)\n",
        "        items = self.load_items_file(items_path)\n",
        "        rating_mat, timestamp_mat = \\\n",
        "            self.load_ratings_file(ratings_path, max(users), max(items))\n",
        "\n",
        "        groups, group_ratings, groups_rated_items_dict, groups_rated_items_set = \\\n",
        "            self.generate_group_ratings(users, rating_mat, timestamp_mat,\n",
        "                                        num_groups=num_groups,\n",
        "                                        group_sizes=group_sizes,\n",
        "                                        min_num_ratings=min_num_ratings)\n",
        "        members, group_ratings_train, group_ratings_val, group_ratings_test, \\\n",
        "            group_negative_items_val, group_negative_items_test, \\\n",
        "            user_ratings_train, user_ratings_val, user_ratings_test, \\\n",
        "            user_negative_items_val, user_negative_items_test = \\\n",
        "            self.split_ratings(group_ratings, rating_mat, timestamp_mat,\n",
        "                               groups, groups_rated_items_dict, groups_rated_items_set,\n",
        "                               train_ratio=train_ratio, val_ratio=val_ratio)\n",
        "\n",
        "        groups_path = os.path.join(output_path, 'groupMember.dat')\n",
        "        group_ratings_train_path = os.path.join(output_path, 'groupRatingTrain.dat')\n",
        "        group_ratings_val_path = os.path.join(output_path, 'groupRatingVal.dat')\n",
        "        group_ratings_test_path = os.path.join(output_path, 'groupRatingTest.dat')\n",
        "        group_negative_items_val_path = os.path.join(output_path, 'groupRatingValNegative.dat')\n",
        "        group_negative_items_test_path = os.path.join(output_path, 'groupRatingTestNegative.dat')\n",
        "        user_ratings_train_path = os.path.join(output_path, 'userRatingTrain.dat')\n",
        "        user_ratings_val_path = os.path.join(output_path, 'userRatingVal.dat')\n",
        "        user_ratings_test_path = os.path.join(output_path, 'userRatingTest.dat')\n",
        "        user_negative_items_val_path = os.path.join(output_path, 'userRatingValNegative.dat')\n",
        "        user_negative_items_test_path = os.path.join(output_path, 'userRatingTestNegative.dat')\n",
        "\n",
        "        self.save_groups(groups_path, groups)\n",
        "        self.save_ratings(group_ratings_train, group_ratings_train_path)\n",
        "        self.save_ratings(group_ratings_val, group_ratings_val_path)\n",
        "        self.save_ratings(group_ratings_test, group_ratings_test_path)\n",
        "        self.save_negative_samples(group_negative_items_val, group_negative_items_val_path)\n",
        "        self.save_negative_samples(group_negative_items_test, group_negative_items_test_path)\n",
        "        self.save_ratings(user_ratings_train, user_ratings_train_path)\n",
        "        self.save_ratings(user_ratings_val, user_ratings_val_path)\n",
        "        self.save_ratings(user_ratings_test, user_ratings_test_path)\n",
        "        self.save_negative_samples(user_negative_items_val, user_negative_items_val_path)\n",
        "        self.save_negative_samples(user_negative_items_test, user_negative_items_test_path)\n",
        "        shutil.copyfile(src=os.path.join(data_path, 'movies.dat'), dst=os.path.join(output_path, 'movies.dat'))\n",
        "        shutil.copyfile(src=os.path.join(data_path, 'users.dat'), dst=os.path.join(output_path, 'users.dat'))\n",
        "\n",
        "        if verbose:\n",
        "            num_group_ratings = len(group_ratings)\n",
        "            num_user_ratings = len(user_ratings_train) + len(user_ratings_val) + len(user_ratings_test)\n",
        "            num_rated_items = len(groups_rated_items_set)\n",
        "\n",
        "            print('Save data: ' + output_path)\n",
        "            print('# Users: ' + str(len(members)))\n",
        "            print('# Items: ' + str(num_rated_items))\n",
        "            print('# Groups: ' + str(len(groups)))\n",
        "            print('# U-I ratings: ' + str(num_user_ratings))\n",
        "            print('# G-I ratings: ' + str(num_group_ratings))\n",
        "            print('Avg. # ratings / user: {:.2f}'.format(num_user_ratings / len(members)))\n",
        "            print('Avg. # ratings / group: {:.2f}'.format(num_group_ratings / len(groups)))\n",
        "            print('Avg. group size: {:.2f}'.format(np.mean(list(map(len, groups)))))\n",
        "\n",
        "    def load_users_file(self, users_path):\n",
        "        users = []\n",
        "\n",
        "        with open(users_path, 'r') as file:\n",
        "            for line in file.readlines():\n",
        "                users.append(int(line.split('::')[0]))\n",
        "\n",
        "        return users\n",
        "\n",
        "    def load_items_file(self, items_path):\n",
        "        items = []\n",
        "\n",
        "        with open(items_path, 'r', encoding='iso-8859-1') as file:\n",
        "            for line in file.readlines():\n",
        "                items.append(int(line.split('::')[0]))\n",
        "\n",
        "        return items\n",
        "\n",
        "    def load_ratings_file(self, ratings_path, max_num_users, max_num_items):\n",
        "        rating_mat = sp.dok_matrix((max_num_users + 1, max_num_items + 1),\n",
        "                                   dtype=np.int)\n",
        "        timestamp_mat = rating_mat.copy()\n",
        "\n",
        "        with open(ratings_path, 'r') as file:\n",
        "            for line in file.readlines():\n",
        "                arr = line.replace('\\n', '').split('::')\n",
        "                user, item, rating, timestamp = \\\n",
        "                    int(arr[0]), int(arr[1]), int(arr[2]), int(arr[3])\n",
        "                rating_mat[user, item] = rating\n",
        "                timestamp_mat[user, item] = timestamp\n",
        "\n",
        "        return rating_mat, timestamp_mat\n",
        "\n",
        "    def generate_group_ratings(self, users, rating_mat, timestamp_mat,\n",
        "                               num_groups, group_sizes, min_num_ratings):\n",
        "        np.random.seed(0)\n",
        "        groups = set()\n",
        "        groups_ratings = []\n",
        "        groups_rated_items_dict = {}\n",
        "        groups_rated_items_set = set()\n",
        "\n",
        "        while len(groups) < num_groups:\n",
        "            group_id = len(groups) + 1\n",
        "\n",
        "            while True:\n",
        "                group = tuple(np.sort(\n",
        "                    np.random.choice(users, np.random.choice(group_sizes),\n",
        "                                     replace=False)))\n",
        "                if group not in groups:\n",
        "                    break\n",
        "\n",
        "            pos_group_rating_counter = Counter()\n",
        "            neg_group_rating_counter = Counter()\n",
        "            group_rating_list = []\n",
        "            group_rated_items = set()\n",
        "\n",
        "            for member in group:\n",
        "                _, items = rating_mat[member, :].nonzero()\n",
        "                pos_items = [item for item in items\n",
        "                             if rating_mat[member, item] >= self.rating_threshold]\n",
        "                neg_items = [item for item in items\n",
        "                             if rating_mat[member, item] < self.rating_threshold]\n",
        "                pos_group_rating_counter.update(pos_items)\n",
        "                neg_group_rating_counter.update(neg_items)\n",
        "\n",
        "            for item, num_ratings in pos_group_rating_counter.items():\n",
        "                if num_ratings == len(group):\n",
        "                    timestamp = max([timestamp_mat[member, item]\n",
        "                                     for member in group])\n",
        "                    group_rated_items.add(item)\n",
        "                    group_rating_list.append((group_id, item, 1, timestamp))\n",
        "\n",
        "            for item, num_ratings in neg_group_rating_counter.items():\n",
        "                if (num_ratings == len(group)) \\\n",
        "                        or (num_ratings + pos_group_rating_counter[item] == len(group)):\n",
        "                    timestamp = max([timestamp_mat[member, item]\n",
        "                                     for member in group])\n",
        "                    group_rated_items.add(item)\n",
        "                    group_rating_list.append((group_id, item, 0, timestamp))\n",
        "\n",
        "            if len(group_rating_list) >= min_num_ratings:\n",
        "                groups.add(group)\n",
        "                groups_rated_items_dict[group_id] = group_rated_items\n",
        "                groups_rated_items_set.update(group_rated_items)\n",
        "                for group_rating in group_rating_list:\n",
        "                    groups_ratings.append(group_rating)\n",
        "\n",
        "        return list(groups), groups_ratings, groups_rated_items_dict, groups_rated_items_set\n",
        "\n",
        "    def split_ratings(self, group_ratings, rating_mat, timestamp_mat,\n",
        "                      groups, groups_rated_items_dict, groups_rated_items_set, train_ratio, val_ratio):\n",
        "        num_group_ratings = len(group_ratings)\n",
        "        num_train = int(num_group_ratings * train_ratio)\n",
        "        num_test = int(num_group_ratings * (1 - train_ratio - val_ratio))\n",
        "\n",
        "        group_ratings = \\\n",
        "            sorted(group_ratings, key=lambda group_rating: group_rating[-1])\n",
        "        group_ratings_train = group_ratings[:num_train]\n",
        "        group_ratings_val = group_ratings[num_train:-num_test]\n",
        "        group_ratings_test = group_ratings[-num_test:]\n",
        "\n",
        "        timestamp_split_train = group_ratings_train[-1][-1]\n",
        "        timestamp_split_val = group_ratings_val[-1][-1]\n",
        "\n",
        "        user_ratings_train = []\n",
        "        user_ratings_val = []\n",
        "        user_ratings_test = []\n",
        "\n",
        "        members = set()\n",
        "        users_rated_items_dict = {}\n",
        "\n",
        "        for group in groups:\n",
        "            for member in group:\n",
        "                if member in members:\n",
        "                    continue\n",
        "                members.add(member)\n",
        "                user_rated_items = set()\n",
        "                _, items = rating_mat[member, :].nonzero()\n",
        "                for item in items:\n",
        "                    if item not in groups_rated_items_set:\n",
        "                        continue\n",
        "                    user_rated_items.add(item)\n",
        "                    if rating_mat[member, item] >= self.rating_threshold:\n",
        "                        rating_tuple = (member, item, 1,\n",
        "                                        timestamp_mat[member, item])\n",
        "                    else:\n",
        "                        rating_tuple = (member, item, 0,\n",
        "                                        timestamp_mat[member, item])\n",
        "                    if timestamp_mat[member, item] <= timestamp_split_train:\n",
        "                        user_ratings_train.append(rating_tuple)\n",
        "                    elif timestamp_split_train < timestamp_mat[member, item] <= timestamp_split_val:\n",
        "                        user_ratings_val.append(rating_tuple)\n",
        "                    else:\n",
        "                        user_ratings_test.append(rating_tuple)\n",
        "\n",
        "                users_rated_items_dict[member] = user_rated_items\n",
        "\n",
        "        np.random.seed(0)\n",
        "\n",
        "        user_negative_items_val = self.get_negative_samples(\n",
        "            user_ratings_val, groups_rated_items_set, users_rated_items_dict)\n",
        "        user_negative_items_test = self.get_negative_samples(\n",
        "            user_ratings_test, groups_rated_items_set, users_rated_items_dict)\n",
        "        group_negative_items_val = self.get_negative_samples(\n",
        "            group_ratings_val, groups_rated_items_set, groups_rated_items_dict)\n",
        "        group_negative_items_test = self.get_negative_samples(\n",
        "            group_ratings_test, groups_rated_items_set, groups_rated_items_dict)\n",
        "\n",
        "        return members, group_ratings_train, group_ratings_val, group_ratings_test, \\\n",
        "            group_negative_items_val, group_negative_items_test, \\\n",
        "            user_ratings_train, user_ratings_val, user_ratings_test, \\\n",
        "            user_negative_items_val, user_negative_items_test\n",
        "\n",
        "    def get_negative_samples(self, ratings, groups_rated_items_set, rated_items_dict):\n",
        "        negative_items_list = []\n",
        "        for sample in ratings:\n",
        "            sample_id, item, _, _ = sample\n",
        "            missed_items = groups_rated_items_set - rated_items_dict[sample_id]\n",
        "            negative_items = \\\n",
        "                np.random.choice(list(missed_items), self.negative_sample_size,\n",
        "                                 replace=(len(missed_items) < self.negative_sample_size))\n",
        "            negative_items_list.append((sample_id, item, negative_items))\n",
        "        return negative_items_list\n",
        "\n",
        "    def save_groups(self, groups_path, groups):\n",
        "        with open(groups_path, 'w') as file:\n",
        "            for i, group in enumerate(groups):\n",
        "                file.write(str(i + 1) + ' '\n",
        "                           + ','.join(map(str, list(group))) + '\\n')\n",
        "\n",
        "    def save_ratings(self, ratings, ratings_path):\n",
        "        with open(ratings_path, 'w') as file:\n",
        "            for rating in ratings:\n",
        "                file.write(' '.join(map(str, list(rating))) + '\\n')\n",
        "\n",
        "    def save_negative_samples(self, negative_items, negative_items_path):\n",
        "        with open(negative_items_path, 'w') as file:\n",
        "            for samples in negative_items:\n",
        "                user, item, negative_items = samples\n",
        "                file.write('({},{}) '.format(user, item)\n",
        "                           + ' '.join(map(str, list(negative_items))) + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BL05MbaZ3Kfk"
      },
      "source": [
        "print('Takes approx. 5 mins...')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sprYbwKFPUU",
        "outputId": "bed68e1c-961c-4011-f139-4b88d2764565"
      },
      "source": [
        "data_folder_path = '.'\n",
        "data_path = os.path.join(data_folder_path, 'ml-1m')\n",
        "data_zip_path = os.path.join(data_folder_path, 'ml-1m.zip')\n",
        "output_path = os.path.join(data_folder_path, 'MovieLens-Rand')\n",
        "\n",
        "if not os.path.exists(data_path):\n",
        "    with zipfile.ZipFile(data_zip_path, 'r') as data_zip:\n",
        "        data_zip.extractall(data_folder_path)\n",
        "        print('Unzip file: ' + data_zip_path)\n",
        "\n",
        "if not os.path.exists(output_path):\n",
        "    os.mkdir(output_path)\n",
        "\n",
        "group_generator = GroupGenerator(data_path, output_path,\n",
        "                                    rating_threshold=4,\n",
        "                                    num_groups=1000,\n",
        "                                    group_sizes=[2, 3, 4, 5],\n",
        "                                    min_num_ratings=20,\n",
        "                                    train_ratio=0.7,\n",
        "                                    val_ratio=0.1,\n",
        "                                    negative_sample_size=100,\n",
        "                                    verbose=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save data: ./MovieLens-Rand\n",
            "# Users: 1626\n",
            "# Items: 1998\n",
            "# Groups: 1000\n",
            "# U-I ratings: 438129\n",
            "# G-I ratings: 53248\n",
            "Avg. # ratings / user: 269.45\n",
            "Avg. # ratings / group: 53.25\n",
            "Avg. group size: 2.19\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8ltpqJ3Ovfx"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3AM4UMwoHEgk"
      },
      "source": [
        "<img src='https://github.com/sparsh-ai/stanza/raw/S758139/images/group_recommender_actorcritic_3.svg'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QupINL9IOvda"
      },
      "source": [
        "class DataLoader(object):\n",
        "    \"\"\"\n",
        "    Data Loader\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        \"\"\"\n",
        "        Initialize DataLoader\n",
        "        :param config: configurations\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.history_length = config.history_length\n",
        "        self.item_num = self.get_item_num()\n",
        "        self.user_num = self.get_user_num()\n",
        "        self.group_num, self.total_group_num, self.group2members_dict, self.user2group_dict = self.get_groups()\n",
        "\n",
        "        if not os.path.exists(self.config.saves_folder_path):\n",
        "            os.mkdir(self.config.saves_folder_path)\n",
        "\n",
        "    def get_item_num(self) -> int:\n",
        "        \"\"\"\n",
        "        Get number of items\n",
        "        :return: number of items\n",
        "        \"\"\"\n",
        "        df_item = pd.read_csv(self.config.item_path, sep='::', index_col=0, engine='python')\n",
        "        self.config.item_num = df_item.index.max()\n",
        "        return self.config.item_num\n",
        "\n",
        "    def get_user_num(self) -> int:\n",
        "        \"\"\"\n",
        "        Get number of users\n",
        "        :return: number of users\n",
        "        \"\"\"\n",
        "        df_user = pd.read_csv(self.config.user_path, sep='::', index_col=0, engine='python')\n",
        "        self.config.user_num = df_user.index.max()\n",
        "        return self.config.user_num\n",
        "\n",
        "    def get_groups(self):\n",
        "        \"\"\"\n",
        "        Get number of groups and group members\n",
        "        :return: group_num, total_group_num, group2members_dict, user2group_dict\n",
        "        \"\"\"\n",
        "        df_group = pd.read_csv(self.config.group_path, sep=' ', header=None, index_col=None,\n",
        "                               names=['GroupID', 'Members'])\n",
        "        df_group['Members'] = df_group['Members']. \\\n",
        "            apply(lambda group_members: tuple(map(int, group_members.split(','))))\n",
        "        group_num = df_group['GroupID'].max()\n",
        "\n",
        "        users = set()\n",
        "        for members in df_group['Members']:\n",
        "            users.update(members)\n",
        "        users = sorted(users)\n",
        "        total_group_num = group_num + len(users)\n",
        "\n",
        "        df_user_group = pd.DataFrame()\n",
        "        df_user_group['GroupID'] = list(range(group_num + 1, total_group_num + 1))\n",
        "        df_user_group['Members'] = [(user,) for user in users]\n",
        "        df_group = df_group.append(df_user_group, ignore_index=True)\n",
        "        group2members_dict = {row['GroupID']: row['Members'] for _, row in df_group.iterrows()}\n",
        "        user2group_dict = {user: group_num + user_index + 1 for user_index, user in enumerate(users)}\n",
        "\n",
        "        self.config.group_num = group_num\n",
        "        self.config.total_group_num = total_group_num\n",
        "        return group_num, total_group_num, group2members_dict, user2group_dict\n",
        "\n",
        "    def load_rating_data(self, mode: str, dataset_name: str, is_appended=True) -> pd.DataFrame():\n",
        "        \"\"\"\n",
        "        Load rating data\n",
        "        :param mode: in ['user', 'group']\n",
        "        :param dataset_name: name of the dataset in ['train', 'val', 'test']\n",
        "        :param is_appended: True to append all datasets before this dataset\n",
        "        :return: df_rating\n",
        "        \"\"\"\n",
        "        assert (mode in ['user', 'group']) and (dataset_name in ['train', 'val', 'test'])\n",
        "        rating_path = os.path.join(self.config.data_folder_path, mode + 'Rating' + dataset_name.capitalize() + '.dat')\n",
        "        df_rating_append = pd.read_csv(rating_path, sep=' ', header=None, index_col=None,\n",
        "                                       names=['GroupID', 'MovieID', 'Rating', 'Timestamp'])\n",
        "        print('Read data:', rating_path)\n",
        "\n",
        "        if is_appended:\n",
        "            if dataset_name == 'train':\n",
        "                df_rating = df_rating_append\n",
        "            elif dataset_name == 'val':\n",
        "                df_rating = self.load_rating_data(mode=mode, dataset_name='train')\n",
        "                df_rating = df_rating.append(df_rating_append, ignore_index=True)\n",
        "            else:\n",
        "                df_rating = self.load_rating_data(mode=mode, dataset_name='val')\n",
        "                df_rating = df_rating.append(df_rating_append, ignore_index=True)\n",
        "        else:\n",
        "            df_rating = df_rating_append\n",
        "\n",
        "        return df_rating\n",
        "\n",
        "    def _load_rating_matrix(self, df_rating: pd.DataFrame()):\n",
        "        \"\"\"\n",
        "        Load rating matrix\n",
        "        :param df_rating: rating data\n",
        "        :return: rating_matrix\n",
        "        \"\"\"\n",
        "        group_ids = df_rating['GroupID']\n",
        "        item_ids = df_rating['MovieID']\n",
        "        ratings = df_rating['Rating']\n",
        "        rating_matrix = coo_matrix((ratings, (group_ids, item_ids)),\n",
        "                                   shape=(self.total_group_num + 1, self.config.item_num + 1)).tocsr()\n",
        "        return rating_matrix\n",
        "\n",
        "    def load_rating_matrix(self, dataset_name: str):\n",
        "        \"\"\"\n",
        "        Load group rating matrix\n",
        "        :param dataset_name: name of the dataset in ['train', 'val', 'test']\n",
        "        :return: rating_matrix\n",
        "        \"\"\"\n",
        "        assert dataset_name in ['train', 'val', 'test']\n",
        "\n",
        "        df_user_rating = self.user2group(self.load_rating_data(mode='user', dataset_name=dataset_name))\n",
        "        df_group_rating = self.load_rating_data(mode='group', dataset_name=dataset_name)\n",
        "        df_group_rating = df_group_rating.append(df_user_rating, ignore_index=True)\n",
        "        rating_matrix = self._load_rating_matrix(df_group_rating)\n",
        "\n",
        "        return rating_matrix\n",
        "\n",
        "    def user2group(self, df_user_rating):\n",
        "        \"\"\"\n",
        "        Change user ids to group ids\n",
        "        :param df_user_rating: user rating\n",
        "        :return: df_user_rating\n",
        "        \"\"\"\n",
        "        df_user_rating['GroupID'] = df_user_rating['GroupID'].apply(lambda user_id: self.user2group_dict[user_id])\n",
        "        return df_user_rating\n",
        "\n",
        "    def _load_eval_data(self, df_data_train: pd.DataFrame(), df_data_eval: pd.DataFrame(),\n",
        "                        negative_samples_dict: Dict[tuple, list]) -> pd.DataFrame():\n",
        "        \"\"\"\n",
        "        Write evaluation data\n",
        "        :param df_data_train: train data\n",
        "        :param df_data_eval: evaluation data\n",
        "        :param negative_samples_dict: one dictionary mapping (group_id, item_id) to negative samples\n",
        "        :return: data for evaluation\n",
        "        \"\"\"\n",
        "        df_eval = pd.DataFrame()\n",
        "        last_state_dict = defaultdict(list)\n",
        "        groups = []\n",
        "        histories = []\n",
        "        actions = []\n",
        "        negative_samples = []\n",
        "\n",
        "        for group_id, rating_group in df_data_train.groupby(['GroupID']):\n",
        "            rating_group.sort_values(by=['Timestamp'], ascending=True, ignore_index=True, inplace=True)\n",
        "            state = rating_group[rating_group['Rating'] == 1]['MovieID'].values.tolist()\n",
        "            last_state_dict[group_id] = state[-self.config.history_length:]\n",
        "\n",
        "        for group_id, rating_group in df_data_eval.groupby(['GroupID']):\n",
        "            rating_group.sort_values(by=['Timestamp'], ascending=True, ignore_index=True, inplace=True)\n",
        "            action = rating_group[rating_group['Rating'] == 1]['MovieID'].values.tolist()\n",
        "            state = deque(maxlen=self.history_length)\n",
        "            state.extend(last_state_dict[group_id])\n",
        "            for item_id in action:\n",
        "                if len(state) == self.config.history_length:\n",
        "                    groups.append(group_id)\n",
        "                    histories.append(list(state))\n",
        "                    actions.append(item_id)\n",
        "                    negative_samples.append(negative_samples_dict[(group_id, item_id)])\n",
        "                state.append(item_id)\n",
        "\n",
        "        df_eval['group'] = groups\n",
        "        df_eval['history'] = histories\n",
        "        df_eval['action'] = actions\n",
        "        df_eval['negative samples'] = negative_samples\n",
        "\n",
        "        return df_eval\n",
        "\n",
        "    def load_negative_samples(self, mode: str, dataset_name: str):\n",
        "        \"\"\"\n",
        "        Load negative samples\n",
        "        :param mode: in ['user', 'group']\n",
        "        :param dataset_name: name of the dataset in ['val', 'test']\n",
        "        :return: negative_samples_dict\n",
        "        \"\"\"\n",
        "        assert (mode in ['user', 'group']) and (dataset_name in ['val', 'test'])\n",
        "        negative_samples_path = os.path.join(self.config.data_folder_path, mode + 'Rating'\n",
        "                                             + dataset_name.capitalize() + 'Negative.dat')\n",
        "        negative_samples_dict = {}\n",
        "\n",
        "        with open(negative_samples_path, 'r') as negative_samples_file:\n",
        "            for line in negative_samples_file.readlines():\n",
        "                negative_samples = line.split()\n",
        "                ids = negative_samples[0][1:-1].split(',')\n",
        "                group_id = int(ids[0])\n",
        "                if mode == 'user':\n",
        "                    group_id = self.user2group_dict[group_id]\n",
        "                item_id = int(ids[1])\n",
        "                negative_samples = list(map(int, negative_samples[1:]))\n",
        "                negative_samples_dict[(group_id, item_id)] = negative_samples\n",
        "\n",
        "        return negative_samples_dict\n",
        "\n",
        "    def load_eval_data(self, mode: str, dataset_name: str, reload=False):\n",
        "        \"\"\"\n",
        "        Load evaluation data\n",
        "        :param mode: in ['user', 'group']\n",
        "        :param dataset_name: in ['val', 'test']\n",
        "        :param reload: True to reload the dataset file\n",
        "        :return: data for evaluation\n",
        "        \"\"\"\n",
        "        assert (mode in ['user', 'group']) and (dataset_name in ['val', 'test'])\n",
        "        exp_eval_path = os.path.join(self.config.saves_folder_path, 'eval_' + mode + '_' + dataset_name + '_'\n",
        "                                     + str(self.config.history_length) + '.pkl')\n",
        "\n",
        "        if reload or not os.path.exists(exp_eval_path):\n",
        "            if dataset_name == 'val':\n",
        "                df_rating_train = self.load_rating_data(mode=mode, dataset_name='train')\n",
        "            else:\n",
        "                df_rating_train = self.load_rating_data(mode=mode, dataset_name='val')\n",
        "            df_rating_eval = self.load_rating_data(mode=mode, dataset_name=dataset_name, is_appended=False)\n",
        "\n",
        "            if mode == 'user':\n",
        "                df_rating_train = self.user2group(df_rating_train)\n",
        "                df_rating_eval = self.user2group(df_rating_eval)\n",
        "\n",
        "            negative_samples_dict = self.load_negative_samples(mode=mode, dataset_name=dataset_name)\n",
        "            df_eval = self._load_eval_data(df_rating_train, df_rating_eval, negative_samples_dict)\n",
        "            df_eval.to_pickle(exp_eval_path)\n",
        "            print('Save data:', exp_eval_path)\n",
        "        else:\n",
        "            df_eval = pd.read_pickle(exp_eval_path)\n",
        "            print('Load data:', exp_eval_path)\n",
        "\n",
        "        return df_eval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6AZOj-gNNRW"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9KZMxY9HiiE"
      },
      "source": [
        "<img src='https://github.com/sparsh-ai/stanza/raw/S758139/images/group_recommender_actorcritic_4.svg'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qjXiULoNEfd"
      },
      "source": [
        "class Actor(nn.Module):\n",
        "    \"\"\"\n",
        "    Actor Network\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedded_state_size: int, action_weight_size: int, hidden_sizes: Tuple[int]):\n",
        "        \"\"\"\n",
        "        Initialize Actor\n",
        "        :param embedded_state_size: embedded state size\n",
        "        :param action_weight_size: embedded action size\n",
        "        :param hidden_sizes: hidden sizes\n",
        "        \"\"\"\n",
        "        super(Actor, self).__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(embedded_state_size, hidden_sizes[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_sizes[1], action_weight_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, embedded_state):\n",
        "        \"\"\"\n",
        "        Forward\n",
        "        :param embedded_state: embedded state\n",
        "        :return: action weight\n",
        "        \"\"\"\n",
        "        return self.net(embedded_state)\n",
        "\n",
        "\n",
        "class Critic(nn.Module):\n",
        "    \"\"\"\n",
        "    Critic Network\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedded_state_size: int, embedded_action_size: int, hidden_sizes: Tuple[int]):\n",
        "        \"\"\"\n",
        "        Initialize Critic\n",
        "        :param embedded_state_size: embedded state size\n",
        "        :param embedded_action_size: embedded action size\n",
        "        :param hidden_sizes: hidden sizes\n",
        "        \"\"\"\n",
        "        super(Critic, self).__init__()\n",
        "\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(embedded_state_size + embedded_action_size, hidden_sizes[0]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_sizes[1], 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, embedded_state, embedded_action):\n",
        "        \"\"\"\n",
        "        Forward\n",
        "        :param embedded_state: embedded state\n",
        "        :param embedded_action: embedded action\n",
        "        :return: Q value\n",
        "        \"\"\"\n",
        "        return self.net(torch.cat([embedded_state, embedded_action], dim=-1))\n",
        "\n",
        "\n",
        "class Embedding(nn.Module):\n",
        "    \"\"\"\n",
        "    Embedding Network\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_size: int, user_num: int, item_num: int):\n",
        "        \"\"\"\n",
        "        Initialize Embedding\n",
        "        :param embedding_size: embedding size\n",
        "        :param user_num: number of users\n",
        "        :param item_num: number of items\n",
        "        \"\"\"\n",
        "        super(Embedding, self).__init__()\n",
        "        self.user_embedding = nn.Embedding(user_num + 1, embedding_size)\n",
        "        self.item_embedding = nn.Embedding(item_num + 1, embedding_size)\n",
        "        self.user_attention = nn.Sequential(\n",
        "            nn.Linear(embedding_size, embedding_size),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(embedding_size, 1)\n",
        "        )\n",
        "        self.user_softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, group_members, history):\n",
        "        \"\"\"\n",
        "        Forward\n",
        "        :param group_members: group members\n",
        "        :param history: browsing history of items\n",
        "        :return: embedded state\n",
        "        \"\"\"\n",
        "        embedded_group_members = self.user_embedding(group_members)\n",
        "        group_member_attentions = self.user_softmax(self.user_attention(embedded_group_members))\n",
        "        embedded_group = torch.squeeze(torch.inner(group_member_attentions.T, embedded_group_members.T))\n",
        "        embedded_history = torch.flatten(self.item_embedding(history), start_dim=-2)\n",
        "        embedded_state = torch.cat([embedded_group, embedded_history], dim=-1)\n",
        "        return embedded_state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMPTwCIqNPqm"
      },
      "source": [
        "## Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GaGRkM9H_RX"
      },
      "source": [
        "<img src='https://github.com/sparsh-ai/stanza/raw/S758139/images/group_recommender_actorcritic_5.svg'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X28pRvrlOQiT"
      },
      "source": [
        "class DDPGAgent(object):\n",
        "    \"\"\"\n",
        "    DDPG (Deep Deterministic Policy Gradient) Agent\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: Config, noise: OUNoise, group2members_dict: dict, verbose=False):\n",
        "        \"\"\"\n",
        "        Initialize DDPGAgent\n",
        "        :param config: configurations\n",
        "        :param group2members_dict: group members data\n",
        "        :param verbose: True to print networks\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "        self.noise = noise\n",
        "        self.group2members_dict = group2members_dict\n",
        "        self.tau = config.tau\n",
        "        self.gamma = config.gamma\n",
        "        self.device = config.device\n",
        "\n",
        "        self.embedding = Embedding(embedding_size=config.embedding_size,\n",
        "                                         user_num=config.user_num,\n",
        "                                         item_num=config.item_num).to(config.device)\n",
        "        self.actor = Actor(embedded_state_size=config.embedded_state_size,\n",
        "                                 action_weight_size=config.embedded_action_size,\n",
        "                                 hidden_sizes=config.actor_hidden_sizes).to(config.device)\n",
        "        self.actor_target = Actor(embedded_state_size=config.embedded_state_size,\n",
        "                                        action_weight_size=config.embedded_action_size,\n",
        "                                        hidden_sizes=config.actor_hidden_sizes).to(config.device)\n",
        "        self.critic = Critic(embedded_state_size=config.embedded_state_size,\n",
        "                                   embedded_action_size=config.embedded_action_size,\n",
        "                                   hidden_sizes=config.critic_hidden_sizes).to(config.device)\n",
        "        self.critic_target = Critic(embedded_state_size=config.embedded_state_size,\n",
        "                                          embedded_action_size=config.embedded_action_size,\n",
        "                                          hidden_sizes=config.critic_hidden_sizes).to(config.device)\n",
        "\n",
        "        if verbose:\n",
        "            print(self.embedding)\n",
        "            print(self.actor)\n",
        "            print(self.critic)\n",
        "\n",
        "        self.copy_network(self.actor, self.actor_target)\n",
        "        self.copy_network(self.critic, self.critic_target)\n",
        "\n",
        "        self.replay_memory = ReplayMemory(buffer_size=config.buffer_size)\n",
        "        self.critic_criterion = nn.MSELoss()\n",
        "        self.embedding_optimizer = optim.Adam(self.embedding.parameters(), lr=config.embedding_learning_rate,\n",
        "                                              weight_decay=config.embedding_weight_decay)\n",
        "        self.actor_optimizer = optim.Adam(self.actor.parameters(), lr=config.actor_learning_rate,\n",
        "                                          weight_decay=config.actor_weight_decay)\n",
        "        self.critic_optimizer = optim.Adam(self.critic.parameters(), lr=config.critic_learning_rate,\n",
        "                                           weight_decay=config.critic_weight_decay)\n",
        "\n",
        "    def copy_network(self, network: nn.Module, network_target: nn.Module):\n",
        "        \"\"\"\n",
        "        Copy one network to its target network\n",
        "        :param network: the original network to be copied\n",
        "        :param network_target: the target network\n",
        "        \"\"\"\n",
        "        for parameters, target_parameters in zip(network.parameters(), network_target.parameters()):\n",
        "            target_parameters.data.copy_(parameters.data)\n",
        "\n",
        "    def sync_network(self, network: nn.Module, network_target: nn.Module):\n",
        "        \"\"\"\n",
        "        Synchronize one network to its target network\n",
        "        :param network: the original network to be synchronized\n",
        "        :param network_target: the target network\n",
        "        :return:\n",
        "        \"\"\"\n",
        "        for parameters, target_parameters in zip(network.parameters(), network_target.parameters()):\n",
        "            target_parameters.data.copy_(parameters.data * self.tau + target_parameters.data * (1 - self.tau))\n",
        "\n",
        "    def get_action(self, state: list, item_candidates: list = None, top_K: int = 1, with_noise=False):\n",
        "        \"\"\"\n",
        "        Get one action\n",
        "        :param state: one environment state\n",
        "        :param item_candidates: item candidates\n",
        "        :param top_K: top K items\n",
        "        :param with_noise: True to with noise\n",
        "        :return: action\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            states = [state]\n",
        "            embedded_states = self.embed_states(states)\n",
        "            action_weights = self.actor(embedded_states)\n",
        "            action_weight = torch.squeeze(action_weights)\n",
        "            if with_noise:\n",
        "                action_weight += self.noise.get_ou_noise()\n",
        "\n",
        "            if item_candidates is None:\n",
        "                item_embedding_weight = self.embedding.item_embedding.weight.clone()\n",
        "            else:\n",
        "                item_candidates = np.array(item_candidates)\n",
        "                item_candidates_tensor = torch.tensor(item_candidates, dtype=torch.int).to(self.device)\n",
        "                item_embedding_weight = self.embedding.item_embedding(item_candidates_tensor)\n",
        "\n",
        "            scores = torch.inner(action_weight, item_embedding_weight).detach().cpu().numpy()\n",
        "            sorted_score_indices = np.argsort(scores)[:top_K]\n",
        "\n",
        "            if item_candidates is None:\n",
        "                action = sorted_score_indices\n",
        "            else:\n",
        "                action = item_candidates[sorted_score_indices]\n",
        "            action = np.squeeze(action)\n",
        "            if top_K == 1:\n",
        "                action = action.item()\n",
        "        return action\n",
        "\n",
        "    def get_embedded_actions(self, embedded_states: torch.Tensor, target=False):\n",
        "        \"\"\"\n",
        "        Get embedded actions\n",
        "        :param embedded_states: embedded states\n",
        "        :param target: True for target network\n",
        "        :return: embedded_actions (, actions)\n",
        "        \"\"\"\n",
        "        if not target:\n",
        "            action_weights = self.actor(embedded_states)\n",
        "        else:\n",
        "            action_weights = self.actor_target(embedded_states)\n",
        "\n",
        "        item_embedding_weight = self.embedding.item_embedding.weight.clone()\n",
        "        scores = torch.inner(action_weights, item_embedding_weight)\n",
        "        embedded_actions = torch.inner(functional.gumbel_softmax(scores, hard=True), item_embedding_weight.t())\n",
        "        return embedded_actions\n",
        "\n",
        "    def embed_state(self, state: list):\n",
        "        \"\"\"\n",
        "        Embed one state\n",
        "        :param state: state\n",
        "        :return: embedded_state\n",
        "        \"\"\"\n",
        "        group_id = state[0]\n",
        "        group_members = torch.tensor(self.group2members_dict[group_id], dtype=torch.int).to(self.device)\n",
        "        history = torch.tensor(state[1:], dtype=torch.int).to(self.device)\n",
        "        embedded_state = self.embedding(group_members, history)\n",
        "        return embedded_state\n",
        "\n",
        "    def embed_states(self, states: List[list]):\n",
        "        \"\"\"\n",
        "        Embed states\n",
        "        :param states: states\n",
        "        :return: embedded_states\n",
        "        \"\"\"\n",
        "        embedded_states = torch.stack([self.embed_state(state) for state in states], dim=0)\n",
        "        return embedded_states\n",
        "\n",
        "    def embed_actions(self, actions: list):\n",
        "        \"\"\"\n",
        "        Embed actions\n",
        "        :param actions: actions\n",
        "        :return: embedded_actions\n",
        "        \"\"\"\n",
        "        actions = torch.tensor(actions, dtype=torch.int).to(self.device)\n",
        "        embedded_actions = self.embedding.item_embedding(actions)\n",
        "        return embedded_actions\n",
        "\n",
        "    def update(self):\n",
        "        \"\"\"\n",
        "        Update the networks\n",
        "        :return: actor loss and critic loss\n",
        "        \"\"\"\n",
        "        batch = self.replay_memory.sample(self.config.batch_size)\n",
        "        states, actions, rewards, next_states = list(zip(*batch))\n",
        "\n",
        "        self.embedding_optimizer.zero_grad()\n",
        "        self.critic_optimizer.zero_grad()\n",
        "        embedded_states = self.embed_states(states)\n",
        "        embedded_actions = self.embed_actions(actions)\n",
        "        rewards = torch.unsqueeze(torch.tensor(rewards, dtype=torch.int).to(self.device), dim=-1)\n",
        "        embedded_next_states = self.embed_states(next_states)\n",
        "        q_values = self.critic(embedded_states, embedded_actions)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            embedded_next_actions = self.get_embedded_actions(embedded_next_states, target=True)\n",
        "            next_q_values = self.critic_target(embedded_next_states, embedded_next_actions)\n",
        "            q_values_target = rewards + self.gamma * next_q_values\n",
        "\n",
        "        critic_loss = self.critic_criterion(q_values, q_values_target)\n",
        "        critic_loss.backward()\n",
        "        self.critic_optimizer.step()\n",
        "\n",
        "        self.actor_optimizer.zero_grad()\n",
        "        embedded_states = self.embed_states(states)\n",
        "        actor_loss = -self.critic(embedded_states, self.get_embedded_actions(embedded_states)).mean()\n",
        "        actor_loss.backward()\n",
        "        self.actor_optimizer.step()\n",
        "        self.embedding_optimizer.step()\n",
        "\n",
        "        self.sync_network(self.actor, self.actor_target)\n",
        "        self.sync_network(self.critic, self.critic_target)\n",
        "\n",
        "        return actor_loss.detach().cpu().numpy(), critic_loss.detach().cpu().numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYiozoLOORHK"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpR7KporIW3w"
      },
      "source": [
        "<img src='https://github.com/sparsh-ai/stanza/raw/S758139/images/group_recommender_actorcritic_6.svg'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4pCAbDEPCvW"
      },
      "source": [
        "class Env(gym.Env):\n",
        "    \"\"\"\n",
        "    Environment for the recommender system\n",
        "    https://github.com/openai/gym/blob/master/gym/core.py\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['human']}\n",
        "    reward_range = (0, 1)\n",
        "\n",
        "    def __init__(self, config: Config, rating_matrix: csr_matrix, dataset_name: str):\n",
        "        \"\"\"\n",
        "        Initialize Env\n",
        "        :param config: configurations\n",
        "        :param rating_matrix: rating matrix\n",
        "        :param dataset_name: dataset name\n",
        "        \"\"\"\n",
        "        assert dataset_name in ['train', 'val', 'test']\n",
        "        self.config = config\n",
        "        self.action_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(config.action_size,))\n",
        "        self.observation_space = gym.spaces.Box(low=-np.inf, high=np.inf, shape=(config.state_size,))\n",
        "\n",
        "        self.rating_matrix = rating_matrix\n",
        "        rating_matrix_coo = rating_matrix.tocoo()\n",
        "        rating_matrix_rows = rating_matrix_coo.row\n",
        "        rating_matrix_columns = rating_matrix_coo.col\n",
        "        self.rating_matrix_index_set = set(zip(*(rating_matrix_rows, rating_matrix_columns)))\n",
        "        self.env_name = 'env_' + dataset_name + '_' + str(self.config.env_n_components) + '.npy'\n",
        "        self.env_path = os.path.join(config.saves_folder_path, self.env_name)\n",
        "\n",
        "        self.rating_matrix_pred = None\n",
        "        self.load_env()\n",
        "\n",
        "        self.state = None\n",
        "        self.reset()\n",
        "\n",
        "    def load_env(self):\n",
        "        \"\"\"\n",
        "        Load environment\n",
        "        \"\"\"\n",
        "        if not os.path.exists(self.env_path):\n",
        "            env_model = NMF(n_components=self.config.env_n_components, init='random', tol=self.config.env_tol,\n",
        "                            max_iter=self.config.env_max_iter, alpha=self.config.env_alpha, verbose=True,\n",
        "                            random_state=0)\n",
        "            print('-' * 50)\n",
        "            print('Train environment:')\n",
        "            W = env_model.fit_transform(X=self.rating_matrix)\n",
        "            H = env_model.components_\n",
        "            self.rating_matrix_pred = W @ H\n",
        "            print('-' * 50)\n",
        "            np.save(self.env_path, self.rating_matrix_pred)\n",
        "            print('Save environment:', self.env_path)\n",
        "        else:\n",
        "            self.rating_matrix_pred = np.load(self.env_path)\n",
        "            print('Load environment:', self.env_path)\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reset the environment\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        while True:\n",
        "            group_id = np.random.choice(range(1, self.config.total_group_num + 1))\n",
        "            nonzero_row, nonzero_col = self.rating_matrix[group_id, :].nonzero()\n",
        "            if len(nonzero_col) >= self.config.history_length:\n",
        "                break\n",
        "        history = np.random.choice(nonzero_col, size=self.config.history_length, replace=False).tolist()\n",
        "        self.state = [group_id] + history\n",
        "        return self.state\n",
        "\n",
        "    def step(self, action: int):\n",
        "        \"\"\"\n",
        "        Take one action to the environment\n",
        "        :param action: action\n",
        "        :return: new_state, reward, done, info\n",
        "        \"\"\"\n",
        "        group_id = self.state[0]\n",
        "        history = self.state[1:]\n",
        "\n",
        "        if (group_id, action) in self.rating_matrix_index_set:\n",
        "            reward = self.rating_matrix[group_id, action]\n",
        "        else:\n",
        "            reward_probability = self.rating_matrix_pred[group_id, action]\n",
        "            reward = np.random.choice(self.config.rewards, p=[1 - reward_probability, reward_probability])\n",
        "\n",
        "        if reward > 0:\n",
        "            history = history[1:] + [action]\n",
        "\n",
        "        new_state = [group_id] + history\n",
        "        self.state = new_state\n",
        "        done = False\n",
        "        info = {}\n",
        "\n",
        "        return new_state, reward, done, info\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        \"\"\"\n",
        "        Render the environment\n",
        "        :param mode: mode\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l1VcWD5PN3_"
      },
      "source": [
        "## Evaluator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kb63DZkrI0Af"
      },
      "source": [
        "<img src='https://github.com/sparsh-ai/stanza/raw/S758139/images/group_recommender_actorcritic_7.svg'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2N_bt1RPU2M"
      },
      "source": [
        "class Evaluator(object):\n",
        "    \"\"\"\n",
        "    Evaluator\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config: Config):\n",
        "        \"\"\"\n",
        "        Initialize Evaluator\n",
        "        :param config: configurations\n",
        "        \"\"\"\n",
        "        self.config = config\n",
        "\n",
        "    def evaluate(self, agent: DDPGAgent, df_eval: pd.DataFrame(), mode: str, top_K=5):\n",
        "        \"\"\"\n",
        "        Evaluate the agent\n",
        "        :param agent: agent\n",
        "        :param df_eval: evaluation data\n",
        "        :param mode: in ['user', 'group']\n",
        "        :param top_K: length of the recommendation list\n",
        "        :return: avg_recall_score, avg_ndcg_score\n",
        "        \"\"\"\n",
        "        recall_scores = []\n",
        "        ndcg_scores = []\n",
        "\n",
        "        for _, row in df_eval.iterrows():\n",
        "            group = row['group']\n",
        "            history = row['history']\n",
        "            item_true = row['action']\n",
        "            item_candidates = row['negative samples'] + [item_true]\n",
        "            np.random.shuffle(item_candidates)\n",
        "\n",
        "            state = [group] + history\n",
        "            items_pred = agent.get_action(state=state, item_candidates=item_candidates, top_K=top_K)\n",
        "\n",
        "            recall_score = 0\n",
        "            ndcg_score = 0\n",
        "\n",
        "            for k, item in enumerate(items_pred):\n",
        "                if item == item_true:\n",
        "                    recall_score = 1\n",
        "                    ndcg_score = np.log2(2) / np.log2(k + 2)\n",
        "                    break\n",
        "\n",
        "            recall_scores.append(recall_score)\n",
        "            ndcg_scores.append(ndcg_score)\n",
        "\n",
        "        avg_recall_score = float(np.mean(recall_scores))\n",
        "        avg_ndcg_score = float(np.mean(ndcg_scores))\n",
        "        print('%s: Recall@%d = %.4f, NDCG@%d = %.4f' % (mode.capitalize(), top_K, avg_recall_score,\n",
        "                                                        top_K, avg_ndcg_score))\n",
        "        return avg_recall_score, avg_ndcg_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Qjxy1kbPVMU"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGyC_wGgJNV6"
      },
      "source": [
        "<img src='https://github.com/sparsh-ai/stanza/raw/S758139/images/group_recommender_actorcritic_8.svg'>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QicC6mQPYFq"
      },
      "source": [
        "def train(config: Config, env: Env, agent: DDPGAgent, evaluator: Evaluator,\n",
        "          df_eval_user: pd.DataFrame(), df_eval_group: pd.DataFrame()):\n",
        "    \"\"\"\n",
        "    Train the agent with the environment\n",
        "    :param config: configurations\n",
        "    :param env: environment\n",
        "    :param agent: agent\n",
        "    :param evaluator: evaluator\n",
        "    :param df_eval_user: user evaluation data\n",
        "    :param df_eval_group: group evaluation data\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    rewards = []\n",
        "    for episode in range(config.num_episodes):\n",
        "        state = env.reset()\n",
        "        agent.noise.reset()\n",
        "        episode_reward = 0\n",
        "\n",
        "        for step in range(config.num_steps):\n",
        "            action = agent.get_action(state)\n",
        "            new_state, reward, _, _ = env.step(action)\n",
        "            agent.replay_memory.push((state, action, reward, new_state))\n",
        "            state = new_state\n",
        "            episode_reward += reward\n",
        "\n",
        "            if len(agent.replay_memory) >= config.batch_size:\n",
        "                agent.update()\n",
        "\n",
        "        rewards.append(episode_reward / config.num_steps)\n",
        "        print('Episode = %d, average reward = %.4f' % (episode, episode_reward / config.num_steps))\n",
        "        if (episode + 1) % config.eval_per_iter == 0:\n",
        "            for top_K in config.top_K_list:\n",
        "                evaluator.evaluate(agent=agent, df_eval=df_eval_user, mode='user', top_K=top_K)\n",
        "            for top_K in config.top_K_list:\n",
        "                evaluator.evaluate(agent=agent, df_eval=df_eval_group, mode='group', top_K=top_K)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t-k7hTLPbQb"
      },
      "source": [
        "## Main"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "31kzTQclPkTJ",
        "outputId": "2f8c0cd9-80d5-47e6-d35e-9a13f59d1e9c"
      },
      "source": [
        "config = Config()\n",
        "dataloader = DataLoader(config)\n",
        "rating_matrix_train = dataloader.load_rating_matrix(dataset_name='val')\n",
        "df_eval_user_test = dataloader.load_eval_data(mode='user', dataset_name='test')\n",
        "df_eval_group_test = dataloader.load_eval_data(mode='group', dataset_name='test')\n",
        "env = Env(config=config, rating_matrix=rating_matrix_train, dataset_name='val')\n",
        "noise = OUNoise(config=config)\n",
        "agent = DDPGAgent(config=config, noise=noise, group2members_dict=dataloader.group2members_dict, verbose=True)\n",
        "evaluator = Evaluator(config=config)\n",
        "train(config=config, env=env, agent=agent, evaluator=evaluator,\n",
        "        df_eval_user=df_eval_user_test, df_eval_group=df_eval_group_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Read data: data/MovieLens-Rand/userRatingVal.dat\n",
            "Read data: data/MovieLens-Rand/userRatingTrain.dat\n",
            "Read data: data/MovieLens-Rand/groupRatingVal.dat\n",
            "Read data: data/MovieLens-Rand/groupRatingTrain.dat\n",
            "Read data: data/MovieLens-Rand/userRatingVal.dat\n",
            "Read data: data/MovieLens-Rand/userRatingTrain.dat\n",
            "Read data: data/MovieLens-Rand/userRatingTest.dat\n",
            "Save data: saves/eval_user_test_5.pkl\n",
            "Read data: data/MovieLens-Rand/groupRatingVal.dat\n",
            "Read data: data/MovieLens-Rand/groupRatingTrain.dat\n",
            "Read data: data/MovieLens-Rand/groupRatingTest.dat\n",
            "Save data: saves/eval_group_test_5.pkl\n",
            "--------------------------------------------------\n",
            "Train environment:\n",
            "violation: 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_nmf.py:1425: FutureWarning: `alpha` was deprecated in version 1.0 and will be removed in 1.2. Use `alpha_W` and `alpha_H` instead\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "violation: 0.44730726017499545\n",
            "violation: 0.25951825473037177\n",
            "violation: 0.1786569624170082\n",
            "violation: 0.13202644434030186\n",
            "violation: 0.1007453956149903\n",
            "violation: 0.08101183925034193\n",
            "violation: 0.06720016324945327\n",
            "violation: 0.05697168218582945\n",
            "violation: 0.04878513468566334\n",
            "violation: 0.04221360480111296\n",
            "violation: 0.0373605827995204\n",
            "violation: 0.033528397871329566\n",
            "violation: 0.030626723806768105\n",
            "violation: 0.02833113784670723\n",
            "violation: 0.026510535567242952\n",
            "violation: 0.024868643868954442\n",
            "violation: 0.023540625200369716\n",
            "violation: 0.02245347513160192\n",
            "violation: 0.021574259106179276\n",
            "violation: 0.0208875325381598\n",
            "violation: 0.020303857265496095\n",
            "violation: 0.01984902195805791\n",
            "violation: 0.019475916810029262\n",
            "violation: 0.01909899407725037\n",
            "violation: 0.018669198653988493\n",
            "violation: 0.018189603579710917\n",
            "violation: 0.01774683852448771\n",
            "violation: 0.017340439632733025\n",
            "violation: 0.016857917606253745\n",
            "violation: 0.016414067062826387\n",
            "violation: 0.016054242686716118\n",
            "violation: 0.015665763380432914\n",
            "violation: 0.015381343946749705\n",
            "violation: 0.015065538977503335\n",
            "violation: 0.014755167118712968\n",
            "violation: 0.014454920846521307\n",
            "violation: 0.014177586910251304\n",
            "violation: 0.013925131116548991\n",
            "violation: 0.01361031490774548\n",
            "violation: 0.01327352812703068\n",
            "violation: 0.012923206151532496\n",
            "violation: 0.012598801859157762\n",
            "violation: 0.012288806832169962\n",
            "violation: 0.01197638684810906\n",
            "violation: 0.011701773935701857\n",
            "violation: 0.011446534888583833\n",
            "violation: 0.011199852256212946\n",
            "violation: 0.01094442605000584\n",
            "violation: 0.010696044905185893\n",
            "violation: 0.010421042430382312\n",
            "violation: 0.010083624909368392\n",
            "violation: 0.009763829207256368\n",
            "violation: 0.009361154186289916\n",
            "violation: 0.008984647120464793\n",
            "violation: 0.008586892529684947\n",
            "violation: 0.008201302194389607\n",
            "violation: 0.007817421253345579\n",
            "violation: 0.007437050480467212\n",
            "violation: 0.007065418629069998\n",
            "violation: 0.006687869283240511\n",
            "violation: 0.006333332979316399\n",
            "violation: 0.005992564013949939\n",
            "violation: 0.005687732582463093\n",
            "violation: 0.005397113788205177\n",
            "violation: 0.005107408619980132\n",
            "violation: 0.004862612333893376\n",
            "violation: 0.0046332477748656205\n",
            "violation: 0.0044227866729825635\n",
            "violation: 0.004233759504198598\n",
            "violation: 0.004061845126631884\n",
            "violation: 0.003903125989212029\n",
            "violation: 0.0037555548918017548\n",
            "violation: 0.0036175996784966577\n",
            "violation: 0.0034843657230495696\n",
            "violation: 0.0033554529805491194\n",
            "violation: 0.003237230159889593\n",
            "violation: 0.0031250858096353363\n",
            "violation: 0.0030199833984355345\n",
            "violation: 0.002920384847825633\n",
            "violation: 0.002829085666103101\n",
            "violation: 0.0027413037548864485\n",
            "violation: 0.0026607674793116326\n",
            "violation: 0.002588736366531167\n",
            "violation: 0.0025190061768252843\n",
            "violation: 0.002450556231537178\n",
            "violation: 0.0023896080642905946\n",
            "violation: 0.002332779984306911\n",
            "violation: 0.00227579297123848\n",
            "violation: 0.0022220111022841615\n",
            "violation: 0.0021725518542756515\n",
            "violation: 0.00212760657431342\n",
            "violation: 0.002086113979596806\n",
            "violation: 0.002046606452699359\n",
            "violation: 0.002007202178305496\n",
            "violation: 0.001970792023948221\n",
            "violation: 0.001937019586213034\n",
            "violation: 0.0019047098435619337\n",
            "violation: 0.0018728937085202237\n",
            "violation: 0.0018439935776105119\n",
            "violation: 0.0018162507750787466\n",
            "violation: 0.0017902108391348323\n",
            "violation: 0.0017671596377588866\n",
            "violation: 0.0017468533081414887\n",
            "violation: 0.0017282444225124095\n",
            "violation: 0.0017127903588604358\n",
            "violation: 0.0017000060105517238\n",
            "violation: 0.0016874602438584022\n",
            "violation: 0.0016783271988684133\n",
            "violation: 0.0016706801869240003\n",
            "violation: 0.0016636056644629708\n",
            "violation: 0.00165419073763739\n",
            "violation: 0.0016454243442044624\n",
            "violation: 0.0016378810744110035\n",
            "violation: 0.0016309860179181187\n",
            "violation: 0.0016226220945474684\n",
            "violation: 0.001617153476716075\n",
            "violation: 0.0016132361060012745\n",
            "violation: 0.0016075802067929714\n",
            "violation: 0.0016033012283314045\n",
            "violation: 0.001600831884076767\n",
            "violation: 0.001598635811983518\n",
            "violation: 0.0015968546267688143\n",
            "violation: 0.0015944892343985986\n",
            "violation: 0.001593303873638313\n",
            "violation: 0.0015930375060283024\n",
            "violation: 0.0015938913701149\n",
            "violation: 0.001595565604770097\n",
            "violation: 0.0015962945323693633\n",
            "violation: 0.0015958233241037908\n",
            "violation: 0.0015940954181069512\n",
            "violation: 0.0015928733973617276\n",
            "violation: 0.0015924716951129555\n",
            "violation: 0.0015924470411741007\n",
            "violation: 0.001593515008163335\n",
            "violation: 0.0015959391336254243\n",
            "violation: 0.0015988621389800503\n",
            "violation: 0.0016026190984927608\n",
            "violation: 0.0016042735172332244\n",
            "violation: 0.0016057331736444858\n",
            "violation: 0.001604251267294013\n",
            "violation: 0.001603046966130058\n",
            "violation: 0.001604006971716017\n",
            "violation: 0.0016042177364964422\n",
            "violation: 0.0016033991874651278\n",
            "violation: 0.0016053299378054314\n",
            "violation: 0.0016047599750235568\n",
            "violation: 0.0016042968770768912\n",
            "violation: 0.001605346125943703\n",
            "violation: 0.0016073640545220204\n",
            "violation: 0.0016084318108987702\n",
            "violation: 0.0016074060616742122\n",
            "violation: 0.001606882076036294\n",
            "violation: 0.0016084827847297736\n",
            "violation: 0.0016071592190145293\n",
            "violation: 0.001606583028875406\n",
            "violation: 0.0016050143507399424\n",
            "violation: 0.0016052274351373026\n",
            "violation: 0.0016046960851488678\n",
            "violation: 0.0016021882916934915\n",
            "violation: 0.0016003452401384824\n",
            "violation: 0.0016005277832216436\n",
            "violation: 0.0016001463772033363\n",
            "violation: 0.0016003193612500772\n",
            "violation: 0.0016004352278518046\n",
            "violation: 0.0016012111843698492\n",
            "violation: 0.0015986606249767314\n",
            "violation: 0.0015957280631199433\n",
            "violation: 0.00159342160899869\n",
            "violation: 0.0015876532168653992\n",
            "violation: 0.0015840773308638486\n",
            "violation: 0.0015799357672286116\n",
            "violation: 0.0015762728985493604\n",
            "violation: 0.0015744162756735338\n",
            "violation: 0.0015718310817723876\n",
            "violation: 0.001569150298636659\n",
            "violation: 0.001567061723489103\n",
            "violation: 0.0015653808771794767\n",
            "violation: 0.001562725567411034\n",
            "violation: 0.0015583275780770864\n",
            "violation: 0.0015551852433477301\n",
            "violation: 0.0015532624815736051\n",
            "violation: 0.0015524244988133406\n",
            "violation: 0.0015537192976138607\n",
            "violation: 0.0015570466423430278\n",
            "violation: 0.0015581375450515438\n",
            "violation: 0.0015593125335399117\n",
            "violation: 0.0015601333853153643\n",
            "violation: 0.0015641911998977999\n",
            "violation: 0.0015697217990975057\n",
            "violation: 0.001575518607049471\n",
            "violation: 0.0015813303847047704\n",
            "violation: 0.001588670554750433\n",
            "violation: 0.00159714756217181\n",
            "violation: 0.0016064115569048108\n",
            "violation: 0.0016158376947765435\n",
            "violation: 0.001626317865527939\n",
            "violation: 0.0016383857931819151\n",
            "violation: 0.0016549120188686416\n",
            "violation: 0.0016736086804752047\n",
            "violation: 0.0016949838777927102\n",
            "violation: 0.0017151923515765614\n",
            "violation: 0.001735596693412234\n",
            "violation: 0.001756602315316708\n",
            "violation: 0.0017754772225851009\n",
            "violation: 0.001791500178535462\n",
            "violation: 0.0018045494325125166\n",
            "violation: 0.001822609364378612\n",
            "violation: 0.0018432492671556265\n",
            "violation: 0.0018600237024105422\n",
            "violation: 0.001875139828046313\n",
            "violation: 0.0018914853325272577\n",
            "violation: 0.0019017650883062522\n",
            "violation: 0.0019162442377921955\n",
            "violation: 0.0019367659167153393\n",
            "violation: 0.001956973107168768\n",
            "violation: 0.0019803817442271736\n",
            "violation: 0.0020098168002260623\n",
            "violation: 0.0020418810475322006\n",
            "violation: 0.002075293829862152\n",
            "violation: 0.002111505174085098\n",
            "violation: 0.002152783131849143\n",
            "violation: 0.002197382429311495\n",
            "violation: 0.002248268490822984\n",
            "violation: 0.0023019283696130194\n",
            "violation: 0.0023590081968809643\n",
            "violation: 0.0024166418666292278\n",
            "violation: 0.002475331933832533\n",
            "violation: 0.0025400692638559478\n",
            "violation: 0.0026020148072405454\n",
            "violation: 0.002664589531653917\n",
            "violation: 0.0027272529894839573\n",
            "violation: 0.0027876877232878884\n",
            "violation: 0.002834092541456462\n",
            "violation: 0.002877035785588566\n",
            "violation: 0.0029121577913810265\n",
            "violation: 0.00294595891202349\n",
            "violation: 0.002973580017307541\n",
            "violation: 0.002982601816176941\n",
            "violation: 0.0029682893847076683\n",
            "violation: 0.0029436260600147488\n",
            "violation: 0.0028953684657878815\n",
            "violation: 0.0028314791629651184\n",
            "violation: 0.0027524307352141883\n",
            "violation: 0.0026566920131128723\n",
            "violation: 0.002503516247240436\n",
            "violation: 0.00240019441932994\n",
            "violation: 0.002265702085575973\n",
            "violation: 0.002148737569817658\n",
            "violation: 0.002041787683908929\n",
            "violation: 0.001885827588444266\n",
            "violation: 0.0017587529058857726\n",
            "violation: 0.0016601532096557517\n",
            "violation: 0.0015730769757928199\n",
            "violation: 0.001493189522584902\n",
            "violation: 0.0014209231064512345\n",
            "violation: 0.001353419141454441\n",
            "violation: 0.001294565724883823\n",
            "violation: 0.0012419615147395509\n",
            "violation: 0.001194815585194679\n",
            "violation: 0.0011509700665622955\n",
            "violation: 0.0011094019214540982\n",
            "violation: 0.001071358887252647\n",
            "violation: 0.0010349161039003454\n",
            "violation: 0.001000712943438635\n",
            "violation: 0.0009673391156831863\n",
            "violation: 0.0009370539178778567\n",
            "violation: 0.00090905602883325\n",
            "violation: 0.0008832720349772361\n",
            "violation: 0.0008589502880128732\n",
            "violation: 0.0008362173553645665\n",
            "violation: 0.0008150967434888066\n",
            "violation: 0.0007955635387676775\n",
            "violation: 0.0007771346699781672\n",
            "violation: 0.0007597991477191826\n",
            "violation: 0.0007437502293355779\n",
            "violation: 0.0007286659600970786\n",
            "violation: 0.0007147273122425742\n",
            "violation: 0.0007018571325193194\n",
            "violation: 0.000689254449255382\n",
            "violation: 0.0006770774292048828\n",
            "violation: 0.0006662800486882662\n",
            "violation: 0.0006559481018960395\n",
            "violation: 0.0006465369228355782\n",
            "violation: 0.0006377492306462243\n",
            "violation: 0.0006292677101082801\n",
            "violation: 0.0006213906781632806\n",
            "violation: 0.0006128628940749894\n",
            "violation: 0.0006054083009205397\n",
            "violation: 0.000598439101053692\n",
            "violation: 0.0005917732234967802\n",
            "violation: 0.0005856476590563272\n",
            "violation: 0.0005799056921979785\n",
            "violation: 0.000574617813777507\n",
            "violation: 0.0005697931314498437\n",
            "violation: 0.0005657852498869211\n",
            "violation: 0.0005618554055905221\n",
            "violation: 0.0005586385104705245\n",
            "violation: 0.0005561436491434105\n",
            "violation: 0.0005542630905013972\n",
            "violation: 0.0005524501414473808\n",
            "violation: 0.0005510103562908905\n",
            "violation: 0.0005499998335599882\n",
            "violation: 0.0005495477658888596\n",
            "violation: 0.0005487533307213594\n",
            "violation: 0.0005478068848446024\n",
            "violation: 0.0005475545903213649\n",
            "violation: 0.0005477424453318858\n",
            "violation: 0.0005481362520232414\n",
            "violation: 0.0005489911397917653\n",
            "violation: 0.0005501809544013014\n",
            "violation: 0.0005512520000530163\n",
            "violation: 0.0005517628637041818\n",
            "violation: 0.0005525001052380965\n",
            "violation: 0.0005534050788702019\n",
            "violation: 0.0005546381127253038\n",
            "violation: 0.0005558078776793008\n",
            "violation: 0.0005566952648214726\n",
            "violation: 0.0005581473856340095\n",
            "violation: 0.0005598696278848962\n",
            "violation: 0.0005610365977018969\n",
            "violation: 0.0005620636675906736\n",
            "violation: 0.0005628145850662422\n",
            "violation: 0.000563728007110425\n",
            "violation: 0.0005640464057299693\n",
            "violation: 0.0005647970375685975\n",
            "violation: 0.0005658886794202271\n",
            "violation: 0.0005671726692372863\n",
            "violation: 0.0005684675170770061\n",
            "violation: 0.0005696384443655234\n",
            "violation: 0.0005707617875018323\n",
            "violation: 0.0005721487897816732\n",
            "violation: 0.0005738250996028881\n",
            "violation: 0.0005756205870212051\n",
            "violation: 0.0005776560498753713\n",
            "violation: 0.0005786445735244343\n",
            "violation: 0.0005788135339514104\n",
            "violation: 0.000579457719957327\n",
            "violation: 0.0005804628577938017\n",
            "violation: 0.000581350451121579\n",
            "violation: 0.0005823636818783266\n",
            "violation: 0.0005835540346078507\n",
            "violation: 0.0005846665656102948\n",
            "violation: 0.0005856150180648709\n",
            "violation: 0.0005866156780535491\n",
            "violation: 0.0005876160235086495\n",
            "violation: 0.0005882984593384227\n",
            "violation: 0.0005892567947142833\n",
            "violation: 0.0005906861756537067\n",
            "violation: 0.0005919938739144872\n",
            "violation: 0.0005934048573281673\n",
            "violation: 0.0005954124630745803\n",
            "violation: 0.0005977087107377683\n",
            "violation: 0.0006002795428310464\n",
            "violation: 0.0006025433682932682\n",
            "violation: 0.0006053274445384045\n",
            "violation: 0.0006080276903527646\n",
            "violation: 0.0006114840007375486\n",
            "violation: 0.0006147586531806763\n",
            "violation: 0.0006177144589450872\n",
            "violation: 0.0006195398212876855\n",
            "violation: 0.000621523280178088\n",
            "violation: 0.0006239015664295397\n",
            "violation: 0.0006262767962552239\n",
            "violation: 0.0006290107179898535\n",
            "violation: 0.0006321145551922367\n",
            "violation: 0.0006354103718612271\n",
            "violation: 0.0006380086479471395\n",
            "violation: 0.0006403985463587491\n",
            "violation: 0.0006427753225340396\n",
            "violation: 0.0006452423743829085\n",
            "violation: 0.0006478939820970669\n",
            "violation: 0.0006501438880589543\n",
            "violation: 0.0006519942012137084\n",
            "violation: 0.0006532938658644055\n",
            "violation: 0.00065390657430765\n",
            "violation: 0.0006538226692506158\n",
            "violation: 0.0006533804516906979\n",
            "violation: 0.0006529321089973609\n",
            "violation: 0.0006523675088838101\n",
            "violation: 0.0006516240201512196\n",
            "violation: 0.0006501759061831021\n",
            "violation: 0.0006484818956583134\n",
            "violation: 0.0006466116184426163\n",
            "violation: 0.0006452907222873361\n",
            "violation: 0.0006427886530316475\n",
            "violation: 0.000639737592781705\n",
            "violation: 0.0006359671934461865\n",
            "violation: 0.0006324477931988836\n",
            "violation: 0.0006294492902478357\n",
            "violation: 0.0006259192201454659\n",
            "violation: 0.0006219671829639615\n",
            "violation: 0.0006180092892278818\n",
            "violation: 0.0006138036540842301\n",
            "violation: 0.0006100257317556844\n",
            "violation: 0.0006065054698780226\n",
            "violation: 0.0006027648488472208\n",
            "violation: 0.0005990503268141397\n",
            "violation: 0.0005953919586944654\n",
            "violation: 0.0005922379256102041\n",
            "violation: 0.0005892146259957418\n",
            "violation: 0.0005861799587426375\n",
            "violation: 0.0005834253941962206\n",
            "violation: 0.0005808651821407349\n",
            "violation: 0.0005785283996921385\n",
            "violation: 0.000575175869806992\n",
            "violation: 0.0005724171832008293\n",
            "violation: 0.0005690993520261153\n",
            "violation: 0.0005658166398073533\n",
            "violation: 0.000561909028645073\n",
            "violation: 0.0005583629769423683\n",
            "violation: 0.000554534518239883\n",
            "violation: 0.0005511331023085466\n",
            "violation: 0.0005479367022439863\n",
            "violation: 0.0005444758960988847\n",
            "violation: 0.0005411918184805183\n",
            "violation: 0.0005377618217002801\n",
            "violation: 0.000534355352061595\n",
            "violation: 0.0005309995538196578\n",
            "violation: 0.0005275051845776918\n",
            "violation: 0.0005239717308602387\n",
            "violation: 0.0005197683765140044\n",
            "violation: 0.0005156402167191936\n",
            "violation: 0.0005109596051867536\n",
            "violation: 0.0005061950882700266\n",
            "violation: 0.0005019658156254942\n",
            "violation: 0.0004978841956533469\n",
            "violation: 0.0004939003051189903\n",
            "violation: 0.0004902324632410935\n",
            "violation: 0.00048652403053509854\n",
            "violation: 0.00048244420801458673\n",
            "violation: 0.00047856171901750923\n",
            "violation: 0.00047502093558129455\n",
            "violation: 0.000471196552338484\n",
            "violation: 0.00046765996924770075\n",
            "violation: 0.00046410081475810815\n",
            "violation: 0.00046059266212922705\n",
            "violation: 0.0004573760428006246\n",
            "violation: 0.00045427721744716206\n",
            "violation: 0.0004511353562411462\n",
            "violation: 0.00044792774949061257\n",
            "violation: 0.0004443879685867963\n",
            "violation: 0.0004412734756334071\n",
            "violation: 0.00043837864799617555\n",
            "violation: 0.000435438685700991\n",
            "violation: 0.0004328324214383571\n",
            "violation: 0.00043019236457726413\n",
            "violation: 0.00042767544486701207\n",
            "violation: 0.00042515215748034456\n",
            "violation: 0.0004218558202381994\n",
            "violation: 0.00041840207472393056\n",
            "violation: 0.0004151560025335518\n",
            "violation: 0.00041225130980069165\n",
            "violation: 0.00040966157988941326\n",
            "violation: 0.00040720079702201016\n",
            "violation: 0.00040486797045706806\n",
            "violation: 0.0004024701554621467\n",
            "violation: 0.00040004661055493987\n",
            "violation: 0.00039778538853987237\n",
            "violation: 0.00039574631851720837\n",
            "violation: 0.0003937783279157492\n",
            "violation: 0.0003920146224952284\n",
            "violation: 0.00039038920562352775\n",
            "violation: 0.00038926547632992317\n",
            "violation: 0.00038776840381086314\n",
            "violation: 0.0003864305575371156\n",
            "violation: 0.00038487655877709185\n",
            "violation: 0.00038313370328094934\n",
            "violation: 0.0003816615306630955\n",
            "violation: 0.0003803066341070547\n",
            "violation: 0.00037901321952079026\n",
            "violation: 0.0003775688388611735\n",
            "violation: 0.00037602189734186323\n",
            "violation: 0.00037428424306647695\n",
            "violation: 0.00037246826749880814\n",
            "violation: 0.00037089044403063227\n",
            "violation: 0.00036949493969442606\n",
            "violation: 0.00036825765627981194\n",
            "violation: 0.00036718715854952826\n",
            "violation: 0.00036630103753030057\n",
            "violation: 0.000365384528513879\n",
            "violation: 0.0003644161654019457\n",
            "violation: 0.00036361902562742\n",
            "violation: 0.00036279218467314594\n",
            "violation: 0.00036213605484704855\n",
            "violation: 0.00036156039617341143\n",
            "violation: 0.00036127142354471994\n",
            "violation: 0.0003613620314037384\n",
            "violation: 0.00036177072218098654\n",
            "violation: 0.00036187112858231075\n",
            "violation: 0.00036194722158017613\n",
            "violation: 0.0003623202397039682\n",
            "violation: 0.00036288920732858223\n",
            "violation: 0.00036358953874052413\n",
            "violation: 0.0003641995321841999\n",
            "violation: 0.00036501763692542996\n",
            "violation: 0.000365926088191074\n",
            "violation: 0.00036690226882095037\n",
            "violation: 0.00036747300649941304\n",
            "violation: 0.00036784495336939947\n",
            "violation: 0.0003683218317489017\n",
            "violation: 0.00036903147952343986\n",
            "violation: 0.0003698063691687093\n",
            "violation: 0.0003708269354020409\n",
            "violation: 0.00037168615066816325\n",
            "violation: 0.0003723782722025441\n",
            "violation: 0.0003731435328211761\n",
            "violation: 0.0003743204388617336\n",
            "violation: 0.00037512660669157327\n",
            "violation: 0.0003763899652013341\n",
            "violation: 0.00037812277006215184\n",
            "violation: 0.0003801459035469458\n",
            "violation: 0.0003822559301445143\n",
            "violation: 0.00038461585254131076\n",
            "violation: 0.00038734175612938483\n",
            "violation: 0.00039034705874526704\n",
            "violation: 0.00039332219450249336\n",
            "violation: 0.0003964747813252766\n",
            "violation: 0.0004000860846165377\n",
            "violation: 0.00040375949063058575\n",
            "violation: 0.0004080863176627153\n",
            "violation: 0.00041274893922261103\n",
            "violation: 0.0004173655502429001\n",
            "violation: 0.0004222290153447954\n",
            "violation: 0.0004275117514750773\n",
            "violation: 0.0004328335730833205\n",
            "violation: 0.00043891932278288757\n",
            "violation: 0.0004444339399281447\n",
            "violation: 0.00045002663170723564\n",
            "violation: 0.00045613920462781067\n",
            "violation: 0.000462470917676749\n",
            "violation: 0.00046918440778555997\n",
            "violation: 0.000476270412120956\n",
            "violation: 0.0004834638558515453\n",
            "violation: 0.0004910000648161085\n",
            "violation: 0.0004989549352920896\n",
            "violation: 0.000507117752609677\n",
            "violation: 0.0005154231135998089\n",
            "violation: 0.0005240766911190505\n",
            "violation: 0.0005329405719841315\n",
            "violation: 0.0005423317020612764\n",
            "violation: 0.0005522317054137783\n",
            "violation: 0.0005630808812827899\n",
            "violation: 0.0005753015419533536\n",
            "violation: 0.0005874335066207011\n",
            "violation: 0.0006011713522096089\n",
            "violation: 0.0006153402263418201\n",
            "violation: 0.0006307743585892897\n",
            "violation: 0.0006455151256425141\n",
            "violation: 0.0006606435130682909\n",
            "violation: 0.0006766123057317512\n",
            "violation: 0.0006929787945976893\n",
            "violation: 0.0007114207519410298\n",
            "violation: 0.0007302435044739566\n",
            "violation: 0.0007508754042721918\n",
            "violation: 0.0007723948351926132\n",
            "violation: 0.0007940364756362986\n",
            "violation: 0.000817486802961598\n",
            "violation: 0.0008418373088538176\n",
            "violation: 0.0008661294106538641\n",
            "violation: 0.0008902859058821203\n",
            "violation: 0.0009171702271293466\n",
            "violation: 0.0009457551845068573\n",
            "violation: 0.0009763745036337127\n",
            "violation: 0.0010090810728045614\n",
            "violation: 0.001043067450851325\n",
            "violation: 0.0010790315795845564\n",
            "violation: 0.00111729317549686\n",
            "violation: 0.0011584360881453713\n",
            "violation: 0.0012033216572690966\n",
            "violation: 0.0012510252687077466\n",
            "violation: 0.001303478780218423\n",
            "violation: 0.0013595543257468768\n",
            "violation: 0.0014201814533430618\n",
            "violation: 0.001479858121938176\n",
            "violation: 0.0015412567082770318\n",
            "violation: 0.001604593230257481\n",
            "violation: 0.0016683279574937746\n",
            "violation: 0.0017315589049753837\n",
            "violation: 0.0017918052407130626\n",
            "violation: 0.0018547092968454791\n",
            "violation: 0.0019166552894839474\n",
            "violation: 0.0019765914980018587\n",
            "violation: 0.002028493293040139\n",
            "violation: 0.0020742369348352684\n",
            "violation: 0.0021148913794521392\n",
            "violation: 0.002151415355101183\n",
            "violation: 0.0021840523154896315\n",
            "violation: 0.002209939264600657\n",
            "violation: 0.0022295906843367865\n",
            "violation: 0.0022272859763589757\n",
            "violation: 0.0022227542757616574\n",
            "violation: 0.0022020266960522494\n",
            "violation: 0.0021719110260931007\n",
            "violation: 0.0021395637855145836\n",
            "violation: 0.0020839971375719137\n",
            "violation: 0.002026296536545544\n",
            "violation: 0.001958654938671584\n",
            "violation: 0.0018915879839730798\n",
            "violation: 0.0018261400887612299\n",
            "violation: 0.0017615416806383338\n",
            "violation: 0.0016986444601442194\n",
            "violation: 0.0016384260154345437\n",
            "violation: 0.0015793136293231044\n",
            "violation: 0.0015230961054473256\n",
            "violation: 0.0014667077205810163\n",
            "violation: 0.0014121439666221881\n",
            "violation: 0.0013582007190963243\n",
            "violation: 0.0013087178495724968\n",
            "violation: 0.0012582081153625427\n",
            "violation: 0.0012086206250048435\n",
            "violation: 0.001160693262499903\n",
            "violation: 0.0011159053702914621\n",
            "violation: 0.0010715109016575033\n",
            "violation: 0.0010289327379155977\n",
            "violation: 0.0009889857778249912\n",
            "violation: 0.0009496881155579783\n",
            "violation: 0.000911737072059529\n",
            "violation: 0.0008746902237946088\n",
            "violation: 0.0008382454721527274\n",
            "violation: 0.0008040889530919713\n",
            "violation: 0.0007703932909612748\n",
            "violation: 0.0007375386450015016\n",
            "violation: 0.000707261091883928\n",
            "violation: 0.0006780922371503059\n",
            "violation: 0.0006498410247215211\n",
            "violation: 0.0006228020033453651\n",
            "violation: 0.0005968341029912452\n",
            "violation: 0.0005722497337172376\n",
            "violation: 0.0005486683105933002\n",
            "violation: 0.0005240112706598004\n",
            "violation: 0.000500837351290729\n",
            "violation: 0.0004790760058353959\n",
            "violation: 0.0004585459796169795\n",
            "violation: 0.000439300113210049\n",
            "violation: 0.00042128148451464885\n",
            "violation: 0.0004042837764649434\n",
            "violation: 0.00038828568729227316\n",
            "violation: 0.00037331734957475246\n",
            "violation: 0.00035927470604150855\n",
            "violation: 0.0003462240293386826\n",
            "violation: 0.00033408677978992993\n",
            "violation: 0.00032269151689621756\n",
            "violation: 0.00031214856966582124\n",
            "violation: 0.0003022218655056024\n",
            "violation: 0.0002929106248573905\n",
            "violation: 0.000284236353765531\n",
            "violation: 0.00027616734447960854\n",
            "violation: 0.00026856734108335925\n",
            "violation: 0.0002614356072838806\n",
            "violation: 0.00025469122052229615\n",
            "violation: 0.00024835454046282906\n",
            "violation: 0.000242374811682774\n",
            "violation: 0.00023671457993936252\n",
            "violation: 0.0002314075132756609\n",
            "violation: 0.0002263496766454157\n",
            "violation: 0.00022166421801754168\n",
            "violation: 0.00021720473767291944\n",
            "violation: 0.00021308817329822018\n",
            "violation: 0.00020920425707177085\n",
            "violation: 0.0002055593404512953\n",
            "violation: 0.00020206911135570025\n",
            "violation: 0.0001987780276063743\n",
            "violation: 0.00019571997287949757\n",
            "violation: 0.0001928452545705827\n",
            "violation: 0.00019014257651260526\n",
            "violation: 0.00018759715187572447\n",
            "violation: 0.00018522488208855476\n",
            "violation: 0.00018301540252481287\n",
            "violation: 0.0001809521651487803\n",
            "violation: 0.00017901893031036748\n",
            "violation: 0.00017720555527914118\n",
            "violation: 0.0001755001760508603\n",
            "violation: 0.00017389864590030348\n",
            "violation: 0.00017239226768947692\n",
            "violation: 0.0001709758067182995\n",
            "violation: 0.00016964747550271444\n",
            "violation: 0.0001683959322434053\n",
            "violation: 0.00016722301531817577\n",
            "violation: 0.00016610446345995786\n",
            "violation: 0.00016505557659111488\n",
            "violation: 0.0001640606109690213\n",
            "violation: 0.00016312511085600308\n",
            "violation: 0.00016224300005441536\n",
            "violation: 0.00016140613618864446\n",
            "violation: 0.0001606091038179687\n",
            "violation: 0.00015985836005004991\n",
            "violation: 0.00015915466075963833\n",
            "violation: 0.00015848890144912732\n",
            "violation: 0.00015786325628227248\n",
            "violation: 0.00015726694614922717\n",
            "violation: 0.00015669732944854355\n",
            "violation: 0.00015615616587566367\n",
            "violation: 0.00015563890144689257\n",
            "violation: 0.0001551455243317052\n",
            "violation: 0.0001546736582398358\n",
            "violation: 0.00015422915019680636\n",
            "violation: 0.00015380486775377677\n",
            "violation: 0.00015339028891668232\n",
            "violation: 0.000153001959374397\n",
            "violation: 0.0001526312991908181\n",
            "violation: 0.00015227506315012687\n",
            "violation: 0.00015193177907973622\n",
            "violation: 0.00015160460773999595\n",
            "violation: 0.00015128749271783732\n",
            "violation: 0.0001509691689118073\n",
            "violation: 0.00015067083823372822\n",
            "violation: 0.00015038489243705925\n",
            "violation: 0.00015010854390877455\n",
            "violation: 0.0001498437907938767\n",
            "violation: 0.00014958664656999015\n",
            "violation: 0.00014933678612296555\n",
            "violation: 0.000149095280351685\n",
            "violation: 0.0001488623124260238\n",
            "violation: 0.00014863788661452325\n",
            "violation: 0.00014842177004108372\n",
            "violation: 0.0001482120595490692\n",
            "violation: 0.00014800913596176368\n",
            "violation: 0.00014781226591470759\n",
            "violation: 0.00014762172578958722\n",
            "violation: 0.00014743830210013262\n",
            "violation: 0.0001472584201712259\n",
            "violation: 0.00014707953107872496\n",
            "violation: 0.00014691233955684542\n",
            "violation: 0.00014674742645752416\n",
            "violation: 0.00014658499846089096\n",
            "violation: 0.0001464254389848152\n",
            "violation: 0.0001462693159004112\n",
            "violation: 0.00014611646994740606\n",
            "violation: 0.0001459659317451706\n",
            "violation: 0.00014581882131998374\n",
            "violation: 0.00014567244636065044\n",
            "violation: 0.00014552971146545579\n",
            "violation: 0.00014538828314017158\n",
            "violation: 0.00014524879815414356\n",
            "violation: 0.00014511169693122975\n",
            "violation: 0.0001449767798773523\n",
            "violation: 0.0001448440030397087\n",
            "violation: 0.00014471338340378217\n",
            "violation: 0.00014458504398724196\n",
            "violation: 0.00014445897576438518\n",
            "violation: 0.00014433421092687086\n",
            "violation: 0.0001442095871956493\n",
            "violation: 0.0001440889504423797\n",
            "violation: 0.00014397012856119047\n",
            "violation: 0.0001438531950341326\n",
            "violation: 0.0001437380271022525\n",
            "violation: 0.00014362431613892953\n",
            "violation: 0.00014351200669704268\n",
            "violation: 0.00014340160618058886\n",
            "violation: 0.0001432924670349054\n",
            "violation: 0.00014318427605784952\n",
            "violation: 0.00014307719755173075\n",
            "violation: 0.00014297096786464978\n",
            "violation: 0.00014286612699039057\n",
            "violation: 0.0001427622715813883\n",
            "violation: 0.00014265965544971038\n",
            "violation: 0.00014255802496531404\n",
            "violation: 0.00014245714854807325\n",
            "violation: 0.00014235702805768158\n",
            "violation: 0.00014225772235316314\n",
            "violation: 0.00014215925271660637\n",
            "violation: 0.0001420616119954052\n",
            "violation: 0.0001419647438389674\n",
            "violation: 0.00014186887403610957\n",
            "violation: 0.00014177356390068747\n",
            "violation: 0.00014167891329646814\n",
            "violation: 0.00014158477644189075\n",
            "violation: 0.00014149088324586146\n",
            "violation: 0.00014139693824587264\n",
            "violation: 0.00014130403022216649\n",
            "violation: 0.00014121168697515542\n",
            "violation: 0.0001411198340632311\n",
            "violation: 0.00014102846205697864\n",
            "violation: 0.0001409376078717793\n",
            "violation: 0.00014084717274224842\n",
            "violation: 0.00014075712035770978\n",
            "violation: 0.000140667428915257\n",
            "violation: 0.0001405781404258915\n",
            "violation: 0.00014048935817862892\n",
            "violation: 0.00014040102253847566\n",
            "violation: 0.00014031301858402002\n",
            "violation: 0.00014022532480439202\n",
            "violation: 0.00014013776778229236\n",
            "violation: 0.00014005078667620718\n",
            "violation: 0.00013996413567500475\n",
            "violation: 0.00013987774991347662\n",
            "violation: 0.00013979158647011263\n",
            "violation: 0.00013970549262048705\n",
            "violation: 0.00013962002223497192\n",
            "violation: 0.00013953472662081286\n",
            "violation: 0.00013944960806162082\n",
            "violation: 0.00013936458116376\n",
            "violation: 0.00013928004860558758\n",
            "violation: 0.00013919578002024628\n",
            "violation: 0.00013911183664728905\n",
            "violation: 0.00013902822213159355\n",
            "violation: 0.0001389448820522964\n",
            "violation: 0.00013886174773462202\n",
            "violation: 0.00013877883019584674\n",
            "violation: 0.0001386956637103772\n",
            "violation: 0.00013861341885115466\n",
            "violation: 0.0001385313652933174\n",
            "violation: 0.00013844937489304894\n",
            "violation: 0.0001383674747444845\n",
            "violation: 0.0001382857232242708\n",
            "violation: 0.00013820413744983331\n",
            "violation: 0.00013812271334900423\n",
            "violation: 0.00013804145339212502\n",
            "violation: 0.00013796033628962222\n",
            "violation: 0.000137879389400587\n",
            "violation: 0.00013779859948139314\n",
            "violation: 0.00013771796122936543\n",
            "violation: 0.00013763748423207777\n",
            "violation: 0.0001375571555675496\n",
            "violation: 0.0001374769687783171\n",
            "violation: 0.00013739693911267025\n",
            "violation: 0.00013731704993748012\n",
            "violation: 0.00013723729327724175\n",
            "violation: 0.00013715764409989584\n",
            "violation: 0.0001370781528662878\n",
            "violation: 0.00013699878907736908\n",
            "violation: 0.00013691955956793495\n",
            "violation: 0.00013684046082079328\n",
            "violation: 0.00013676147830313104\n",
            "violation: 0.00013668263089154737\n",
            "violation: 0.0001366039167547656\n",
            "violation: 0.00013652531810384467\n",
            "violation: 0.00013644683144242508\n",
            "violation: 0.00013636828474114266\n",
            "violation: 0.00013629007276160822\n",
            "violation: 0.0001362119867667798\n",
            "violation: 0.0001361340343987845\n",
            "violation: 0.0001360561960466911\n",
            "violation: 0.00013597846560640866\n",
            "violation: 0.00013590084282607079\n",
            "violation: 0.00013582332799697952\n",
            "violation: 0.0001357459172461061\n",
            "violation: 0.00013566861452636925\n",
            "violation: 0.00013559141357031022\n",
            "violation: 0.0001355143138812395\n",
            "violation: 0.00013543731747760922\n",
            "violation: 0.00013536042534652816\n",
            "violation: 0.00013528363595388055\n",
            "violation: 0.00013520694744829478\n",
            "violation: 0.0001351303541323704\n",
            "violation: 0.00013505385110157815\n",
            "violation: 0.00013497744354592058\n",
            "violation: 0.0001349011381246199\n",
            "violation: 0.00013482490637056754\n",
            "violation: 0.00013474876692740368\n",
            "violation: 0.00013467274834505957\n",
            "violation: 0.00013459683005899952\n",
            "violation: 0.0001345209989322887\n",
            "violation: 0.00013444525409348173\n",
            "violation: 0.0001343695968426146\n",
            "violation: 0.00013429403160071475\n",
            "violation: 0.00013421855980551395\n",
            "violation: 0.0001341431762130529\n",
            "violation: 0.00013406788254808442\n",
            "violation: 0.00013399267335654488\n",
            "violation: 0.00013391755164561325\n",
            "violation: 0.00013384251931531445\n",
            "violation: 0.0001337675762737859\n",
            "violation: 0.00013369272081626993\n",
            "violation: 0.00013361795043446005\n",
            "violation: 0.00013354326996009374\n",
            "violation: 0.00013346867239195654\n",
            "violation: 0.0001333941563483292\n",
            "violation: 0.00013331972222664767\n",
            "violation: 0.00013324537032537105\n",
            "violation: 0.0001331710996072335\n",
            "violation: 0.00013309691152900739\n",
            "violation: 0.00013302280698854565\n",
            "violation: 0.00013294878132316318\n",
            "violation: 0.0001328748351435202\n",
            "violation: 0.00013280096976641423\n",
            "violation: 0.00013272718531828512\n",
            "violation: 0.00013265348202466364\n",
            "violation: 0.00013257985774992734\n",
            "violation: 0.0001325063117136258\n",
            "violation: 0.00013243284434173188\n",
            "violation: 0.00013235945724713577\n",
            "violation: 0.00013228614844346793\n",
            "violation: 0.00013221291905199826\n",
            "violation: 0.0001321397695224831\n",
            "violation: 0.0001320666986244514\n",
            "violation: 0.00013199370834815076\n",
            "violation: 0.0001319207944514608\n",
            "violation: 0.00013184795864180316\n",
            "violation: 0.00013177519956606673\n",
            "violation: 0.00013170251784681389\n",
            "violation: 0.00013162991354926043\n",
            "violation: 0.00013155738576077275\n",
            "violation: 0.00013148493676465948\n",
            "violation: 0.000131412563477223\n",
            "violation: 0.00013134026635557854\n",
            "violation: 0.00013126804413849644\n",
            "violation: 0.00013119589857723475\n",
            "violation: 0.00013112382776197864\n",
            "violation: 0.00013105183170669448\n",
            "violation: 0.00013097991104283685\n",
            "violation: 0.00013090806698148666\n",
            "violation: 0.00013083630365973362\n",
            "violation: 0.00013076461446713037\n",
            "violation: 0.0001306930050726293\n",
            "violation: 0.00013062147083365796\n",
            "violation: 0.00013055000979070292\n",
            "violation: 0.00013047862281683904\n",
            "violation: 0.00013040730898157272\n",
            "violation: 0.00013033606801758014\n",
            "violation: 0.0001302648997803092\n",
            "violation: 0.00013019380487701957\n",
            "violation: 0.0001301227837166223\n",
            "violation: 0.0001300518358918482\n",
            "violation: 0.0001299809606119119\n",
            "violation: 0.0001299101575189877\n",
            "violation: 0.00012983942599924936\n",
            "violation: 0.0001297687659130941\n",
            "violation: 0.00012969817703453867\n",
            "violation: 0.00012962765915794567\n",
            "violation: 0.00012955721290218374\n",
            "violation: 0.00012948683783587842\n",
            "violation: 0.00012941653403304818\n",
            "violation: 0.00012934630195208987\n",
            "violation: 0.00012927614187210635\n",
            "violation: 0.00012920605260801602\n",
            "violation: 0.00012913603396814602\n",
            "violation: 0.0001290660872976113\n",
            "violation: 0.00012899621093461367\n",
            "violation: 0.00012892640462623428\n",
            "violation: 0.00012885666803551216\n",
            "violation: 0.000128787001120186\n",
            "violation: 0.00012871740436170624\n",
            "violation: 0.00012864787733620235\n",
            "violation: 0.00012857841993927805\n",
            "violation: 0.00012850903213401915\n",
            "violation: 0.00012843971400109292\n",
            "violation: 0.0001283704650020754\n",
            "violation: 0.0001283012848903045\n",
            "violation: 0.00012823217360753301\n",
            "violation: 0.00012816313165002087\n",
            "violation: 0.00012809415946263988\n",
            "violation: 0.00012802525597597003\n",
            "violation: 0.00012795642106924615\n",
            "violation: 0.00012788765447170996\n",
            "violation: 0.00012781895594234154\n",
            "violation: 0.0001277503256039616\n",
            "violation: 0.00012768176391964357\n",
            "violation: 0.00012761327048555396\n",
            "violation: 0.00012754484486058508\n",
            "violation: 0.00012747648716577282\n",
            "violation: 0.00012740819688472716\n",
            "violation: 0.0001273399740506173\n",
            "violation: 0.00012727181857721196\n",
            "violation: 0.00012720373057457728\n",
            "violation: 0.00012713570972801928\n",
            "violation: 0.00012706775578618095\n",
            "violation: 0.0001269998687361354\n",
            "violation: 0.00012693204843257358\n",
            "violation: 0.00012686429479692322\n",
            "violation: 0.00012679660783455858\n",
            "violation: 0.00012672898771884527\n",
            "violation: 0.00012666143405231728\n",
            "violation: 0.00012659394669461743\n",
            "violation: 0.0001265265255769825\n",
            "violation: 0.00012645917080860518\n",
            "violation: 0.00012639188289151568\n",
            "violation: 0.00012632466079273\n",
            "violation: 0.00012625750440257378\n",
            "violation: 0.00012619041383918393\n",
            "violation: 0.0001261233889453905\n",
            "violation: 0.0001260564296736938\n",
            "violation: 0.00012598953582761054\n",
            "violation: 0.00012592270731418627\n",
            "violation: 0.00012585594392277327\n",
            "violation: 0.0001257892459026752\n",
            "violation: 0.00012572261308687327\n",
            "violation: 0.00012565604516866861\n",
            "violation: 0.00012558954205375814\n",
            "violation: 0.000125523103655692\n",
            "violation: 0.00012545672989570643\n",
            "violation: 0.00012539042063254362\n",
            "violation: 0.00012532417575106356\n",
            "violation: 0.00012525799526397503\n",
            "violation: 0.00012519187917898715\n",
            "violation: 0.0001251258274051404\n",
            "violation: 0.00012505983983538156\n",
            "violation: 0.00012499391605508332\n",
            "violation: 0.0001249280559451896\n",
            "violation: 0.0001248622594078703\n",
            "violation: 0.00012479652643908277\n",
            "violation: 0.00012473085705476\n",
            "violation: 0.00012466525119138165\n",
            "violation: 0.00012459970875095696\n",
            "violation: 0.00012453422958663148\n",
            "violation: 0.00012446881359832692\n",
            "violation: 0.00012440346073066123\n",
            "violation: 0.00012433817089163202\n",
            "violation: 0.00012427294405937923\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_nmf.py:1641: ConvergenceWarning: Maximum number of iterations 1000 reached. Increase it to improve convergence.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Save environment: saves/env_val_32.npy\n",
            "Embedding(\n",
            "  (user_embedding): Embedding(6041, 32)\n",
            "  (item_embedding): Embedding(3953, 32)\n",
            "  (user_attention): Sequential(\n",
            "    (0): Linear(in_features=32, out_features=32, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=32, out_features=1, bias=True)\n",
            "  )\n",
            "  (user_softmax): Softmax(dim=-1)\n",
            ")\n",
            "Actor(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=192, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=64, out_features=32, bias=True)\n",
            "  )\n",
            ")\n",
            "Critic(\n",
            "  (net): Sequential(\n",
            "    (0): Linear(in_features=224, out_features=32, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=16, out_features=1, bias=True)\n",
            "  )\n",
            ")\n",
            "Episode = 0, average reward = 0.0100\n",
            "Episode = 1, average reward = 0.0400\n",
            "Episode = 2, average reward = 0.0400\n",
            "Episode = 3, average reward = 0.0000\n",
            "Episode = 4, average reward = 0.0200\n",
            "Episode = 5, average reward = 0.0500\n",
            "Episode = 6, average reward = 0.0100\n",
            "Episode = 7, average reward = 0.0000\n",
            "Episode = 8, average reward = 0.0000\n",
            "Episode = 9, average reward = 0.0000\n",
            "User: Recall@5 = 0.0470, NDCG@5 = 0.0271\n",
            "User: Recall@10 = 0.0932, NDCG@10 = 0.0418\n",
            "User: Recall@20 = 0.1920, NDCG@20 = 0.0665\n",
            "Group: Recall@5 = 0.0442, NDCG@5 = 0.0249\n",
            "Group: Recall@10 = 0.0874, NDCG@10 = 0.0386\n",
            "Group: Recall@20 = 0.1808, NDCG@20 = 0.0620\n",
            "Episode = 10, average reward = 0.0000\n",
            "Episode = 11, average reward = 0.0000\n",
            "Episode = 12, average reward = 0.0000\n",
            "Episode = 13, average reward = 0.0000\n",
            "Episode = 14, average reward = 0.0000\n",
            "Episode = 15, average reward = 0.0000\n",
            "Episode = 16, average reward = 0.0000\n",
            "Episode = 17, average reward = 0.0000\n",
            "Episode = 18, average reward = 0.0000\n",
            "Episode = 19, average reward = 0.0000\n",
            "User: Recall@5 = 0.0468, NDCG@5 = 0.0273\n",
            "User: Recall@10 = 0.0942, NDCG@10 = 0.0424\n",
            "User: Recall@20 = 0.1943, NDCG@20 = 0.0674\n",
            "Group: Recall@5 = 0.0462, NDCG@5 = 0.0254\n",
            "Group: Recall@10 = 0.0896, NDCG@10 = 0.0391\n",
            "Group: Recall@20 = 0.1859, NDCG@20 = 0.0631\n",
            "Episode = 20, average reward = 0.0000\n",
            "Episode = 21, average reward = 0.0000\n",
            "Episode = 22, average reward = 0.0000\n",
            "Episode = 23, average reward = 0.0000\n",
            "Episode = 24, average reward = 0.0000\n",
            "Episode = 25, average reward = 0.0000\n",
            "Episode = 26, average reward = 0.0000\n",
            "Episode = 27, average reward = 0.0000\n",
            "Episode = 28, average reward = 0.0000\n",
            "Episode = 29, average reward = 0.0000\n",
            "User: Recall@5 = 0.0467, NDCG@5 = 0.0276\n",
            "User: Recall@10 = 0.0950, NDCG@10 = 0.0430\n",
            "User: Recall@20 = 0.1981, NDCG@20 = 0.0687\n",
            "Group: Recall@5 = 0.0447, NDCG@5 = 0.0254\n",
            "Group: Recall@10 = 0.0914, NDCG@10 = 0.0403\n",
            "Group: Recall@20 = 0.1893, NDCG@20 = 0.0649\n",
            "Episode = 30, average reward = 0.0000\n",
            "Episode = 31, average reward = 0.0000\n",
            "Episode = 32, average reward = 0.0000\n",
            "Episode = 33, average reward = 0.0000\n",
            "Episode = 34, average reward = 0.0000\n",
            "Episode = 35, average reward = 0.0000\n",
            "Episode = 36, average reward = 0.0000\n",
            "Episode = 37, average reward = 0.0000\n",
            "Episode = 38, average reward = 0.0000\n",
            "Episode = 39, average reward = 0.0000\n",
            "User: Recall@5 = 0.0478, NDCG@5 = 0.0283\n",
            "User: Recall@10 = 0.0975, NDCG@10 = 0.0441\n",
            "User: Recall@20 = 0.2040, NDCG@20 = 0.0708\n",
            "Group: Recall@5 = 0.0454, NDCG@5 = 0.0269\n",
            "Group: Recall@10 = 0.0962, NDCG@10 = 0.0432\n",
            "Group: Recall@20 = 0.1969, NDCG@20 = 0.0684\n",
            "Episode = 40, average reward = 0.0000\n",
            "Episode = 41, average reward = 0.0000\n",
            "Episode = 42, average reward = 0.0000\n",
            "Episode = 43, average reward = 0.0000\n",
            "Episode = 44, average reward = 0.0000\n",
            "Episode = 45, average reward = 0.0000\n",
            "Episode = 46, average reward = 0.0000\n",
            "Episode = 47, average reward = 0.0000\n",
            "Episode = 48, average reward = 0.0000\n",
            "Episode = 49, average reward = 0.0000\n",
            "User: Recall@5 = 0.0487, NDCG@5 = 0.0293\n",
            "User: Recall@10 = 0.1037, NDCG@10 = 0.0468\n",
            "User: Recall@20 = 0.2062, NDCG@20 = 0.0724\n",
            "Group: Recall@5 = 0.0530, NDCG@5 = 0.0313\n",
            "Group: Recall@10 = 0.1067, NDCG@10 = 0.0483\n",
            "Group: Recall@20 = 0.2008, NDCG@20 = 0.0718\n",
            "Episode = 50, average reward = 0.0000\n",
            "Episode = 51, average reward = 0.0000\n",
            "Episode = 52, average reward = 0.0000\n",
            "Episode = 53, average reward = 0.0000\n",
            "Episode = 54, average reward = 0.0000\n",
            "Episode = 55, average reward = 0.0000\n",
            "Episode = 56, average reward = 0.0000\n",
            "Episode = 57, average reward = 0.0000\n",
            "Episode = 58, average reward = 0.0000\n",
            "Episode = 59, average reward = 0.0000\n",
            "User: Recall@5 = 0.0527, NDCG@5 = 0.0317\n",
            "User: Recall@10 = 0.1081, NDCG@10 = 0.0494\n",
            "User: Recall@20 = 0.2093, NDCG@20 = 0.0747\n",
            "Group: Recall@5 = 0.0598, NDCG@5 = 0.0364\n",
            "Group: Recall@10 = 0.1104, NDCG@10 = 0.0524\n",
            "Group: Recall@20 = 0.2079, NDCG@20 = 0.0769\n",
            "Episode = 60, average reward = 0.0000\n",
            "Episode = 61, average reward = 0.0000\n",
            "Episode = 62, average reward = 0.0000\n",
            "Episode = 63, average reward = 0.0000\n",
            "Episode = 64, average reward = 0.0000\n",
            "Episode = 65, average reward = 0.0000\n",
            "Episode = 66, average reward = 0.0000\n",
            "Episode = 67, average reward = 0.0000\n",
            "Episode = 68, average reward = 0.0000\n",
            "Episode = 69, average reward = 0.0000\n",
            "User: Recall@5 = 0.0576, NDCG@5 = 0.0351\n",
            "User: Recall@10 = 0.1116, NDCG@10 = 0.0524\n",
            "User: Recall@20 = 0.2108, NDCG@20 = 0.0773\n",
            "Group: Recall@5 = 0.0660, NDCG@5 = 0.0421\n",
            "Group: Recall@10 = 0.1192, NDCG@10 = 0.0590\n",
            "Group: Recall@20 = 0.2123, NDCG@20 = 0.0821\n",
            "Episode = 70, average reward = 0.0000\n",
            "Episode = 71, average reward = 0.0000\n",
            "Episode = 72, average reward = 0.0000\n",
            "Episode = 73, average reward = 0.0000\n",
            "Episode = 74, average reward = 0.0000\n",
            "Episode = 75, average reward = 0.0000\n",
            "Episode = 76, average reward = 0.0000\n",
            "Episode = 77, average reward = 0.0000\n",
            "Episode = 78, average reward = 0.0000\n",
            "Episode = 79, average reward = 0.0000\n",
            "User: Recall@5 = 0.0634, NDCG@5 = 0.0391\n",
            "User: Recall@10 = 0.1172, NDCG@10 = 0.0562\n",
            "User: Recall@20 = 0.2140, NDCG@20 = 0.0804\n",
            "Group: Recall@5 = 0.0738, NDCG@5 = 0.0481\n",
            "Group: Recall@10 = 0.1241, NDCG@10 = 0.0641\n",
            "Group: Recall@20 = 0.2140, NDCG@20 = 0.0866\n",
            "Episode = 80, average reward = 0.0000\n",
            "Episode = 81, average reward = 0.0000\n",
            "Episode = 82, average reward = 0.0000\n",
            "Episode = 83, average reward = 0.0000\n",
            "Episode = 84, average reward = 0.0000\n",
            "Episode = 85, average reward = 0.0000\n",
            "Episode = 86, average reward = 0.0000\n",
            "Episode = 87, average reward = 0.0000\n",
            "Episode = 88, average reward = 0.0000\n",
            "Episode = 89, average reward = 0.0000\n",
            "User: Recall@5 = 0.0707, NDCG@5 = 0.0437\n",
            "User: Recall@10 = 0.1209, NDCG@10 = 0.0598\n",
            "User: Recall@20 = 0.2160, NDCG@20 = 0.0835\n",
            "Group: Recall@5 = 0.0855, NDCG@5 = 0.0554\n",
            "Group: Recall@10 = 0.1348, NDCG@10 = 0.0710\n",
            "Group: Recall@20 = 0.2213, NDCG@20 = 0.0926\n",
            "Episode = 90, average reward = 0.0000\n",
            "Episode = 91, average reward = 0.0000\n",
            "Episode = 92, average reward = 0.0000\n",
            "Episode = 93, average reward = 0.0000\n",
            "Episode = 94, average reward = 0.0000\n",
            "Episode = 95, average reward = 0.0000\n",
            "Episode = 96, average reward = 0.0000\n",
            "Episode = 97, average reward = 0.0000\n",
            "Episode = 98, average reward = 0.0000\n",
            "Episode = 99, average reward = 0.0000\n",
            "User: Recall@5 = 0.0771, NDCG@5 = 0.0479\n",
            "User: Recall@10 = 0.1253, NDCG@10 = 0.0634\n",
            "User: Recall@20 = 0.2195, NDCG@20 = 0.0869\n",
            "Group: Recall@5 = 0.0982, NDCG@5 = 0.0629\n",
            "Group: Recall@10 = 0.1426, NDCG@10 = 0.0771\n",
            "Group: Recall@20 = 0.2240, NDCG@20 = 0.0975\n",
            "Episode = 100, average reward = 0.0000\n",
            "Episode = 101, average reward = 0.0000\n",
            "Episode = 102, average reward = 0.0000\n",
            "Episode = 103, average reward = 0.0000\n",
            "Episode = 104, average reward = 0.0000\n",
            "Episode = 105, average reward = 0.0000\n",
            "Episode = 106, average reward = 0.0000\n",
            "Episode = 107, average reward = 0.0000\n",
            "Episode = 108, average reward = 0.0000\n",
            "Episode = 109, average reward = 0.0000\n",
            "User: Recall@5 = 0.0830, NDCG@5 = 0.0526\n",
            "User: Recall@10 = 0.1328, NDCG@10 = 0.0684\n",
            "User: Recall@20 = 0.2243, NDCG@20 = 0.0913\n",
            "Group: Recall@5 = 0.1060, NDCG@5 = 0.0688\n",
            "Group: Recall@10 = 0.1566, NDCG@10 = 0.0852\n",
            "Group: Recall@20 = 0.2325, NDCG@20 = 0.1040\n",
            "Episode = 110, average reward = 0.0000\n",
            "Episode = 111, average reward = 0.0000\n",
            "Episode = 112, average reward = 0.0000\n",
            "Episode = 113, average reward = 0.0000\n",
            "Episode = 114, average reward = 0.0000\n",
            "Episode = 115, average reward = 0.0000\n",
            "Episode = 116, average reward = 0.0000\n",
            "Episode = 117, average reward = 0.0000\n",
            "Episode = 118, average reward = 0.0000\n",
            "Episode = 119, average reward = 0.0100\n",
            "User: Recall@5 = 0.0885, NDCG@5 = 0.0568\n",
            "User: Recall@10 = 0.1420, NDCG@10 = 0.0739\n",
            "User: Recall@20 = 0.2307, NDCG@20 = 0.0961\n",
            "Group: Recall@5 = 0.1177, NDCG@5 = 0.0751\n",
            "Group: Recall@10 = 0.1707, NDCG@10 = 0.0922\n",
            "Group: Recall@20 = 0.2401, NDCG@20 = 0.1096\n",
            "Episode = 120, average reward = 0.0000\n",
            "Episode = 121, average reward = 0.0000\n",
            "Episode = 122, average reward = 0.0000\n",
            "Episode = 123, average reward = 0.0000\n",
            "Episode = 124, average reward = 0.0000\n",
            "Episode = 125, average reward = 0.0000\n",
            "Episode = 126, average reward = 0.0000\n",
            "Episode = 127, average reward = 0.0200\n",
            "Episode = 128, average reward = 0.0000\n",
            "Episode = 129, average reward = 0.0000\n",
            "User: Recall@5 = 0.0950, NDCG@5 = 0.0607\n",
            "User: Recall@10 = 0.1472, NDCG@10 = 0.0774\n",
            "User: Recall@20 = 0.2390, NDCG@20 = 0.1004\n",
            "Group: Recall@5 = 0.1255, NDCG@5 = 0.0809\n",
            "Group: Recall@10 = 0.1778, NDCG@10 = 0.0979\n",
            "Group: Recall@20 = 0.2540, NDCG@20 = 0.1170\n",
            "Episode = 130, average reward = 0.0000\n",
            "Episode = 131, average reward = 0.0000\n",
            "Episode = 132, average reward = 0.0100\n",
            "Episode = 133, average reward = 0.0100\n",
            "Episode = 134, average reward = 0.0000\n",
            "Episode = 135, average reward = 0.0000\n",
            "Episode = 136, average reward = 0.0000\n",
            "Episode = 137, average reward = 0.0000\n",
            "Episode = 138, average reward = 0.0200\n",
            "Episode = 139, average reward = 0.0800\n",
            "User: Recall@5 = 0.0997, NDCG@5 = 0.0633\n",
            "User: Recall@10 = 0.1540, NDCG@10 = 0.0807\n",
            "User: Recall@20 = 0.2480, NDCG@20 = 0.1042\n",
            "Group: Recall@5 = 0.1324, NDCG@5 = 0.0848\n",
            "Group: Recall@10 = 0.1915, NDCG@10 = 0.1038\n",
            "Group: Recall@20 = 0.2689, NDCG@20 = 0.1232\n",
            "Episode = 140, average reward = 0.0100\n",
            "Episode = 141, average reward = 0.0200\n",
            "Episode = 142, average reward = 0.0000\n",
            "Episode = 143, average reward = 0.0000\n",
            "Episode = 144, average reward = 0.0000\n",
            "Episode = 145, average reward = 0.0200\n",
            "Episode = 146, average reward = 0.1100\n",
            "Episode = 147, average reward = 0.0400\n",
            "Episode = 148, average reward = 0.0000\n",
            "Episode = 149, average reward = 0.0400\n",
            "User: Recall@5 = 0.1038, NDCG@5 = 0.0657\n",
            "User: Recall@10 = 0.1602, NDCG@10 = 0.0839\n",
            "User: Recall@20 = 0.2613, NDCG@20 = 0.1092\n",
            "Group: Recall@5 = 0.1387, NDCG@5 = 0.0890\n",
            "Group: Recall@10 = 0.2032, NDCG@10 = 0.1098\n",
            "Group: Recall@20 = 0.2926, NDCG@20 = 0.1321\n",
            "Episode = 150, average reward = 0.1000\n",
            "Episode = 151, average reward = 0.0300\n",
            "Episode = 152, average reward = 0.0200\n",
            "Episode = 153, average reward = 0.0000\n",
            "Episode = 154, average reward = 1.0000\n",
            "Episode = 155, average reward = 0.0700\n",
            "Episode = 156, average reward = 0.0300\n",
            "Episode = 157, average reward = 0.0300\n",
            "Episode = 158, average reward = 0.0000\n",
            "Episode = 159, average reward = 0.0100\n",
            "User: Recall@5 = 0.1068, NDCG@5 = 0.0675\n",
            "User: Recall@10 = 0.1728, NDCG@10 = 0.0886\n",
            "User: Recall@20 = 0.2787, NDCG@20 = 0.1152\n",
            "Group: Recall@5 = 0.1417, NDCG@5 = 0.0912\n",
            "Group: Recall@10 = 0.2233, NDCG@10 = 0.1175\n",
            "Group: Recall@20 = 0.3302, NDCG@20 = 0.1445\n",
            "Episode = 160, average reward = 0.0000\n",
            "Episode = 161, average reward = 0.1300\n",
            "Episode = 162, average reward = 0.0000\n",
            "Episode = 163, average reward = 0.0800\n",
            "Episode = 164, average reward = 1.0000\n",
            "Episode = 165, average reward = 0.0000\n",
            "Episode = 166, average reward = 0.0000\n",
            "Episode = 167, average reward = 0.0000\n",
            "Episode = 168, average reward = 0.0000\n",
            "Episode = 169, average reward = 0.0400\n",
            "User: Recall@5 = 0.1121, NDCG@5 = 0.0701\n",
            "User: Recall@10 = 0.1872, NDCG@10 = 0.0942\n",
            "User: Recall@20 = 0.2908, NDCG@20 = 0.1203\n",
            "Group: Recall@5 = 0.1495, NDCG@5 = 0.0945\n",
            "Group: Recall@10 = 0.2511, NDCG@10 = 0.1273\n",
            "Group: Recall@20 = 0.3569, NDCG@20 = 0.1541\n",
            "Episode = 170, average reward = 0.1000\n",
            "Episode = 171, average reward = 0.0400\n",
            "Episode = 172, average reward = 0.0200\n",
            "Episode = 173, average reward = 0.0000\n",
            "Episode = 174, average reward = 0.0000\n",
            "Episode = 175, average reward = 0.1300\n",
            "Episode = 176, average reward = 0.0000\n",
            "Episode = 177, average reward = 0.0000\n",
            "Episode = 178, average reward = 0.0000\n",
            "Episode = 179, average reward = 1.0000\n",
            "User: Recall@5 = 0.1175, NDCG@5 = 0.0727\n",
            "User: Recall@10 = 0.1994, NDCG@10 = 0.0990\n",
            "User: Recall@20 = 0.3052, NDCG@20 = 0.1256\n",
            "Group: Recall@5 = 0.1583, NDCG@5 = 0.0989\n",
            "Group: Recall@10 = 0.2714, NDCG@10 = 0.1355\n",
            "Group: Recall@20 = 0.3764, NDCG@20 = 0.1622\n",
            "Episode = 180, average reward = 0.0000\n",
            "Episode = 181, average reward = 0.0100\n",
            "Episode = 182, average reward = 0.0000\n",
            "Episode = 183, average reward = 0.0000\n",
            "Episode = 184, average reward = 1.0000\n",
            "Episode = 185, average reward = 0.0000\n",
            "Episode = 186, average reward = 0.0000\n",
            "Episode = 187, average reward = 0.0400\n",
            "Episode = 188, average reward = 0.9900\n",
            "Episode = 189, average reward = 0.0800\n",
            "User: Recall@5 = 0.1230, NDCG@5 = 0.0752\n",
            "User: Recall@10 = 0.2088, NDCG@10 = 0.1029\n",
            "User: Recall@20 = 0.3134, NDCG@20 = 0.1292\n",
            "Group: Recall@5 = 0.1671, NDCG@5 = 0.1040\n",
            "Group: Recall@10 = 0.2851, NDCG@10 = 0.1422\n",
            "Group: Recall@20 = 0.3879, NDCG@20 = 0.1683\n",
            "Episode = 190, average reward = 0.0100\n",
            "Episode = 191, average reward = 0.0600\n",
            "Episode = 192, average reward = 0.0000\n",
            "Episode = 193, average reward = 0.0000\n",
            "Episode = 194, average reward = 0.0500\n",
            "Episode = 195, average reward = 0.0000\n",
            "Episode = 196, average reward = 0.0200\n",
            "Episode = 197, average reward = 0.0000\n",
            "Episode = 198, average reward = 0.0000\n",
            "Episode = 199, average reward = 0.0400\n",
            "User: Recall@5 = 0.1272, NDCG@5 = 0.0774\n",
            "User: Recall@10 = 0.2173, NDCG@10 = 0.1065\n",
            "User: Recall@20 = 0.3285, NDCG@20 = 0.1346\n",
            "Group: Recall@5 = 0.1742, NDCG@5 = 0.1079\n",
            "Group: Recall@10 = 0.2943, NDCG@10 = 0.1470\n",
            "Group: Recall@20 = 0.4148, NDCG@20 = 0.1776\n",
            "Episode = 200, average reward = 0.0000\n",
            "Episode = 201, average reward = 0.1500\n",
            "Episode = 202, average reward = 0.0000\n",
            "Episode = 203, average reward = 0.0000\n",
            "Episode = 204, average reward = 0.0400\n",
            "Episode = 205, average reward = 0.0200\n",
            "Episode = 206, average reward = 0.0100\n",
            "Episode = 207, average reward = 0.0100\n",
            "Episode = 208, average reward = 0.0200\n",
            "Episode = 209, average reward = 0.0000\n",
            "User: Recall@5 = 0.1293, NDCG@5 = 0.0788\n",
            "User: Recall@10 = 0.2268, NDCG@10 = 0.1101\n",
            "User: Recall@20 = 0.3381, NDCG@20 = 0.1383\n",
            "Group: Recall@5 = 0.1778, NDCG@5 = 0.1106\n",
            "Group: Recall@10 = 0.3048, NDCG@10 = 0.1519\n",
            "Group: Recall@20 = 0.4304, NDCG@20 = 0.1842\n",
            "Episode = 210, average reward = 0.1100\n",
            "Episode = 211, average reward = 0.0200\n",
            "Episode = 212, average reward = 0.0000\n",
            "Episode = 213, average reward = 0.0000\n",
            "Episode = 214, average reward = 0.3200\n",
            "Episode = 215, average reward = 0.0100\n",
            "Episode = 216, average reward = 0.0100\n",
            "Episode = 217, average reward = 0.0000\n",
            "Episode = 218, average reward = 0.0000\n",
            "Episode = 219, average reward = 0.0400\n",
            "User: Recall@5 = 0.1304, NDCG@5 = 0.0796\n",
            "User: Recall@10 = 0.2349, NDCG@10 = 0.1132\n",
            "User: Recall@20 = 0.3470, NDCG@20 = 0.1416\n",
            "Group: Recall@5 = 0.1856, NDCG@5 = 0.1149\n",
            "Group: Recall@10 = 0.3153, NDCG@10 = 0.1568\n",
            "Group: Recall@20 = 0.4448, NDCG@20 = 0.1901\n",
            "Episode = 220, average reward = 0.0200\n",
            "Episode = 221, average reward = 0.0000\n",
            "Episode = 222, average reward = 0.0000\n",
            "Episode = 223, average reward = 0.0100\n",
            "Episode = 224, average reward = 0.0000\n",
            "Episode = 225, average reward = 0.0000\n",
            "Episode = 226, average reward = 0.0000\n",
            "Episode = 227, average reward = 0.0000\n",
            "Episode = 228, average reward = 0.1300\n",
            "Episode = 229, average reward = 0.0000\n",
            "User: Recall@5 = 0.1328, NDCG@5 = 0.0810\n",
            "User: Recall@10 = 0.2405, NDCG@10 = 0.1156\n",
            "User: Recall@20 = 0.3595, NDCG@20 = 0.1458\n",
            "Group: Recall@5 = 0.1876, NDCG@5 = 0.1170\n",
            "Group: Recall@10 = 0.3249, NDCG@10 = 0.1613\n",
            "Group: Recall@20 = 0.4619, NDCG@20 = 0.1964\n",
            "Episode = 230, average reward = 0.3000\n",
            "Episode = 231, average reward = 0.0000\n",
            "Episode = 232, average reward = 0.0200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nl1YCO20Zwtq"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7cZKFdhZwtv",
        "outputId": "010839a5-e2f8-4bc4-8ea1-b78aa47335cf"
      },
      "source": [
        "!pip install -q watermark\n",
        "%reload_ext watermark\n",
        "%watermark -a \"Sparsh A.\" -m -iv -u -t -d"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "markdown 3.3.6 requires importlib-metadata>=4.4; python_version < \"3.10\", but you have importlib-metadata 2.1.2 which is incompatible.\u001b[0m\n",
            "Author: Sparsh A.\n",
            "\n",
            "Last updated: 2021-11-26 13:20:10\n",
            "\n",
            "Compiler    : GCC 7.5.0\n",
            "OS          : Linux\n",
            "Release     : 5.4.104+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n",
            "torch  : 1.10.0+cu111\n",
            "IPython: 5.5.0\n",
            "pandas : 1.1.5\n",
            "gym    : 0.17.3\n",
            "numpy  : 1.19.5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6maUiF9Zwtw"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOsXA5uEZwtw"
      },
      "source": [
        "**END**"
      ]
    }
  ]
}